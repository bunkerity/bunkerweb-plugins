-- BunkerWeb Malware Scan - Cache Module
-- Handles all caching operations including local cache and Redis/Valkey shared cache
-- Includes circuit breaker, composite cache, attacker tracking, and differential TTL

local cjson = require("cjson")
local utils = require("bunkerweb.utils")

local ngx = ngx
local ERR = ngx.ERR
local NOTICE = ngx.NOTICE
local WARN = ngx.WARN
local tonumber = tonumber
local tostring = tostring

-- Module table
local cache = {}

-- ============================================================================
-- CIRCUIT BREAKER FUNCTIONS
-- Protects against Redis failures with exponential backoff
-- ============================================================================

-- Get Redis circuit breaker state from local cache.
-- Returns failure_count and last_failure_time.
function cache.get_redis_circuit_breaker_state(plugin)
	local cb_key = "plugin_malware_scan_redis_circuit_breaker"
	local ok, data = plugin.cachestore:get(cb_key)
	if not ok or not data then
		return 0, 0  -- No failures recorded
	end

	-- Data format: "failure_count:last_failure_time"
	local count, time = data:match("^(%d+):(%d+)$")
	if not count or not time then
		return 0, 0
	end

	return tonumber(count) or 0, tonumber(time) or 0
end

-- Update Redis circuit breaker state in local cache.
-- Sets failure_count and last_failure_time.
function cache.set_redis_circuit_breaker_state(plugin, failure_count, last_failure_time)
	local cb_key = "plugin_malware_scan_redis_circuit_breaker"
	local data = tostring(failure_count) .. ":" .. tostring(last_failure_time)
	-- Store for 60 seconds (longer than max backoff of 8s default)
	plugin.cachestore:set(cb_key, data, 60)
end

-- Check if Redis should be skipped based on circuit breaker state.
-- Returns true if Redis should be skipped, false otherwise.
-- Implements exponential backoff: 1ms, 2ms, 4ms, 8ms, 16ms, 32ms, 64ms, 128ms, 256ms, 512ms, 1s, 2s, 4s, up to max (default 8s).
function cache.should_skip_redis(plugin)
	local failure_count, last_failure_time = cache.get_redis_circuit_breaker_state(plugin)

	if failure_count == 0 then
		return false  -- No failures, try Redis
	end

	local now = ngx.time()
	local max_backoff = tonumber(plugin.variables["MALWARE_SCAN_REDIS_CIRCUIT_BREAKER_MAX_BACKOFF"]) or 8
	-- Cap failure_count to prevent integer overflow in exponential backoff (Medium severity issue #12)
	local capped_failure_count = math.min(failure_count, 20)
	-- Start at 1ms (0.001s) and double each time: 0.001 * 2^failure_count
	local backoff_seconds = math.min(0.001 * (2 ^ capped_failure_count), max_backoff)
	local time_since_failure = now - last_failure_time

	if time_since_failure >= backoff_seconds then
		return false  -- Backoff period expired, try Redis again
	end

	-- Still in backoff period
	plugin:log_debug(string.format(
		"[CACHE_SHARED] Skipping Redis (circuit breaker): %d consecutive failures, backoff %.3fs, %.3fs remaining",
		failure_count, backoff_seconds, backoff_seconds - time_since_failure
	))
	return true
end

-- Record a successful Redis operation (resets circuit breaker).
function cache.record_redis_success(plugin)
	cache.set_redis_circuit_breaker_state(plugin, 0, 0)
	plugin:log_debug("[CACHE_SHARED] Redis operation successful, circuit breaker reset")
end

-- Record a failed Redis operation (increments circuit breaker).
function cache.record_redis_failure(plugin)
	local failure_count, last_failure_time = cache.get_redis_circuit_breaker_state(plugin)
	local now = ngx.time()
	failure_count = failure_count + 1

	cache.set_redis_circuit_breaker_state(plugin, failure_count, now)

	local max_backoff = tonumber(plugin.variables["MALWARE_SCAN_REDIS_CIRCUIT_BREAKER_MAX_BACKOFF"]) or 8
	local backoff_seconds = math.min(0.001 * (2 ^ failure_count), max_backoff)

	-- Implement log throttling to prevent log flooding (Low severity issue #22)
	-- Only log if: first failure, every 5th failure, or 60+ seconds since last log
	local should_log = (failure_count == 1) or
	                   (failure_count % 5 == 0) or
	                   (last_failure_time > 0 and (now - last_failure_time) >= 60)

	if should_log then
		-- Format backoff time appropriately (ms for small values, s for large)
		local backoff_str
		if backoff_seconds < 1 then
			backoff_str = string.format("%.0fms", backoff_seconds * 1000)
		else
			backoff_str = string.format("%.1fs", backoff_seconds)
		end

		plugin.logger:log(ERR, string.format(
			"[CACHE_SHARED] Redis failure #%d recorded, backing off for %s",
			failure_count, backoff_str
		))
	end
end

-- ============================================================================
-- COMPOSITE REDIS CACHE FUNCTIONS
-- Single lookup/write for all scanner results (performance optimization)
-- ============================================================================

-- Get composite scan results from Redis (all scanners in one lookup).
-- Returns success boolean, results table (or nil), and error message.
-- Results table format: {vt="result", threatfox="result", sentinelone="result"}
function cache.get_composite_redis_cache(plugin, checksum)
	local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
	local use_redis = plugin.variables["USE_REDIS"] == "yes"

	if not use_shared or not use_redis then
		return false, nil, "shared cache disabled"
	end

	-- Check circuit breaker before attempting Redis
	if cache.should_skip_redis(plugin) then
		return false, nil, "circuit breaker open"
	end

	local cache_key = "plugin_malware_scan_results_" .. checksum
	plugin:log_debug(string.format("[CACHE_SHARED] Attempting composite Redis lookup for %s...", checksum:sub(1, 16) .. "..."))

	local ok, data = plugin.datastore:get(cache_key)
	if not ok then
		cache.record_redis_failure(plugin)
		return false, nil, "redis lookup failed"
	end

	if not data then
		-- Cache miss (not an error)
		cache.record_redis_success(plugin)
		return true, nil, nil
	end

	-- Parse JSON
	local decode_ok, results = pcall(cjson.decode, data)
	if not decode_ok then
		plugin.logger:log(ERR, "[CACHE_SHARED] Failed to parse composite cache JSON: " .. tostring(results))
		cache.record_redis_success(plugin)  -- Redis worked, just bad data
		return false, nil, "json parse error"
	end

	-- Validate JSON decoded to expected data structure (Medium severity issue #11)
	if type(results) ~= "table" then
		plugin.logger:log(ERR, "[CACHE_SHARED] Invalid data type after JSON decode: " .. type(results))
		cache.record_redis_success(plugin)  -- Redis worked, just bad data
		return false, nil, "invalid data structure"
	end

	cache.record_redis_success(plugin)
	local count = (results.vt and 1 or 0) + (results.threatfox and 1 or 0) + (results.sentinelone and 1 or 0)
	plugin:log_debug(string.format("[CACHE_SHARED] Composite cache HIT (%d scanner results)", count))
	return true, results, nil
end

-- Store composite scan results in Redis (all scanners in one write).
-- Takes checksum and results table: {vt="result", threatfox="result", sentinelone="result"}
-- Returns success boolean and error message.
function cache.set_composite_redis_cache(plugin, checksum, results)
	local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
	local use_redis = plugin.variables["USE_REDIS"] == "yes"

	if not use_shared or not use_redis then
		return true  -- Not an error, just disabled
	end

	-- Skip if circuit breaker is open
	if cache.should_skip_redis(plugin) then
		return true  -- Not a fatal error
	end

	local cache_key = "plugin_malware_scan_results_" .. checksum
	local shared_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_SHARED_TTL"]) or 21600

	-- Encode as JSON
	local encode_ok, json_data = pcall(cjson.encode, results)
	if not encode_ok then
		plugin.logger:log(ERR, "[CACHE_SHARED] Failed to encode composite cache JSON: " .. tostring(json_data))
		return false, "json encode error"
	end

	plugin:log_debug(string.format("[CACHE_SHARED] Storing composite results in Redis (TTL=%ds)...", shared_ttl))

	local ok, err = plugin.datastore:set(cache_key, json_data, shared_ttl)
	if not ok then
		plugin.logger:log(ERR, "[CACHE_SHARED] Failed to store composite results in Redis: " .. tostring(err))
		cache.record_redis_failure(plugin)
		return false, err
	end

	plugin.logger:log(ERR, string.format("[CACHE_SHARED] Composite results stored in Redis (TTL=%ds)", shared_ttl))
	cache.record_redis_success(plugin)
	return true, nil
end

-- ============================================================================
-- ATTACKER IP TRACKING
-- Tracks IPs that upload malware, with separate IPv4/IPv6 namespaces
-- ============================================================================

-- Detect if an IP address is IPv4 or IPv6.
-- Returns "ipv4" or "ipv6"
function cache.detect_ip_version(ip)
	-- IPv6 addresses contain colons
	if ip:match(":") then
		return "ipv6"
	else
		return "ipv4"
	end
end

-- Track attacker IP that uploaded malware.
-- Stores IP address, timestamp of last upload, and array of SHA256 checksums.
-- Data is stored in local cache and optionally in Redis when shared cache is enabled.
-- IPv4 and IPv6 addresses are stored in separate key namespaces for better organization.
function cache.track_attacker_ip(plugin, client_ip, checksum)
	local track_enabled = plugin.variables["MALWARE_SCAN_TRACK_ATTACKERS"] == "yes"
	if not track_enabled then
		return true  -- Feature disabled, not an error
	end

	local attacker_ttl = tonumber(plugin.variables["MALWARE_SCAN_TRACK_ATTACKER_TTL"]) or 7776000  -- 90 days default

	-- Separate IPv4 and IPv6 into different key namespaces
	local ip_version = cache.detect_ip_version(client_ip)
	local cache_key = "plugin_malware_scan_attacker_" .. ip_version .. "_" .. client_ip

	-- Get existing attacker data from local cache
	local existing_data = nil
	local ok, cached = plugin.cachestore:get(cache_key)
	if ok and cached then
		local decode_ok, decoded = pcall(cjson.decode, cached)
		if decode_ok then
			existing_data = decoded
		end
	end

	-- If not in local cache, try Redis (if shared cache enabled)
	if not existing_data then
		local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
		local use_redis = plugin.variables["USE_REDIS"] == "yes"

		if use_shared and use_redis and not cache.should_skip_redis(plugin) then
			local redis_ok, redis_data = plugin.datastore:get(cache_key)
			if redis_ok and redis_data then
				local decode_ok, decoded = pcall(cjson.decode, redis_data)
				if decode_ok then
					existing_data = decoded
					cache.record_redis_success(plugin)
				end
			elseif not redis_ok then
				cache.record_redis_failure(plugin)
			else
				cache.record_redis_success(plugin)
			end
		end
	end

	-- Create or update attacker data
	local current_time = os.time()
	local attacker_data = existing_data or {
		first_upload = current_time,
		last_upload = current_time,
		checksums = {},
		upload_count = 0
	}

	-- Update last upload timestamp (preserves first_upload from existing data)
	attacker_data.last_upload = current_time

	-- Ensure first_upload exists (backwards compatibility for old cache entries)
	if not attacker_data.first_upload then
		attacker_data.first_upload = current_time
	end

	-- Add checksum if not already present (avoid duplicates)
	local checksum_exists = false
	for _, existing_checksum in ipairs(attacker_data.checksums) do
		if existing_checksum == checksum then
			checksum_exists = true
			break
		end
	end

	if not checksum_exists then
		table.insert(attacker_data.checksums, checksum)
		attacker_data.upload_count = attacker_data.upload_count + 1
	end

	-- Encode as JSON
	local encode_ok, json_data = pcall(cjson.encode, attacker_data)
	if not encode_ok then
		plugin.logger:log(ERR, "[ATTACKER_TRACK] Failed to encode attacker data: " .. tostring(json_data))
		return false
	end

	-- Store in local cache
	local store_ok, store_err = plugin.cachestore:set(cache_key, json_data, attacker_ttl)
	if not store_ok then
		plugin.logger:log(ERR, "[ATTACKER_TRACK] Failed to store in local cache: " .. tostring(store_err))
	end

	-- Store in Redis if shared cache enabled
	local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
	local use_redis = plugin.variables["USE_REDIS"] == "yes"

	if use_shared and use_redis and not cache.should_skip_redis(plugin) then
		local redis_ok, redis_err = plugin.datastore:set(cache_key, json_data, attacker_ttl)
		if redis_ok then
			cache.record_redis_success(plugin)
			plugin.logger:log(NOTICE, string.format("[ATTACKER_TRACK] %s %s tracked: %d unique malware uploads (TTL=%ds, stored in Redis)",
				ip_version:upper(), client_ip, attacker_data.upload_count, attacker_ttl))
		else
			cache.record_redis_failure(plugin)
			plugin.logger:log(ERR, "[ATTACKER_TRACK] Failed to store in Redis: " .. tostring(redis_err))
		end
	else
		plugin.logger:log(NOTICE, string.format("[ATTACKER_TRACK] %s %s tracked: %d unique malware uploads (TTL=%ds, local only)",
			ip_version:upper(), client_ip, attacker_data.upload_count, attacker_ttl))
	end

	return true
end

-- Get attacker data for a specific IP.
-- Returns attacker data table or nil if not found.
-- Checks local cache first, then Redis if enabled.
-- IPv4 and IPv6 addresses are stored in separate key namespaces.
function cache.get_attacker_data(plugin, client_ip)
	local track_enabled = plugin.variables["MALWARE_SCAN_TRACK_ATTACKERS"] == "yes"
	if not track_enabled then
		return nil  -- Feature disabled
	end

	-- Separate IPv4 and IPv6 into different key namespaces
	local ip_version = cache.detect_ip_version(client_ip)
	local cache_key = "plugin_malware_scan_attacker_" .. ip_version .. "_" .. client_ip

	-- Check local cache first
	local ok, cached = plugin.cachestore:get(cache_key)
	if ok and cached then
		local decode_ok, decoded = pcall(cjson.decode, cached)
		if decode_ok then
			return decoded
		end
	end

	-- Try Redis if shared cache enabled
	local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
	local use_redis = plugin.variables["USE_REDIS"] == "yes"

	if use_shared and use_redis and not cache.should_skip_redis(plugin) then
		local redis_ok, redis_data = plugin.datastore:get(cache_key)
		if redis_ok and redis_data then
			local decode_ok, decoded = pcall(cjson.decode, redis_data)
			if decode_ok then
				cache.record_redis_success(plugin)
				-- Cache locally for faster subsequent lookups
				local ttl = tonumber(plugin.variables["MALWARE_SCAN_TRACK_ATTACKER_TTL"]) or 7776000  -- 90 days default
				plugin.cachestore:set(cache_key, redis_data, ttl)
				return decoded
			end
		elseif not redis_ok then
			cache.record_redis_failure(plugin)
		else
			cache.record_redis_success(plugin)
		end
	end

	return nil  -- Not found
end

-- ============================================================================
-- LOCAL CACHE FUNCTIONS
-- Fast local cache operations with differential TTL for clean/malicious files
-- ============================================================================

-- Check if file scan result is in local cache.
-- Returns success boolean and cached value or nil.
function cache.is_in_cache(plugin, file_path)
	local ok, data = plugin.cachestore:get("plugin_malware_scan_file_" .. file_path)
	if not ok then
		return false, nil
	end
	return true, data
end

-- Add scan result to local cache.
-- Returns success boolean and error message if failed.
function cache.add_to_cache(plugin, file_path, value)
	local ok, err = plugin.cachestore:set(
		"plugin_malware_scan_file_" .. file_path,
		value,
		3600
	)
	if not ok then
		return false, err
	end
	return true
end

-- Check if ClamAV scan result is in local cache (by SHA256 checksum).
-- Returns success boolean, cached result, and file size (for verification).
-- Cache format: "result|size|timestamp"
function cache.is_in_clamav_cache(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_clamav_" .. checksum
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|size|timestamp"
		local result, cached_size, timestamp = data:match("^([^|]+)|([^|]+)|([^|]+)$")
		if result then
			-- Verify file size matches (prevents collisions and provides quick filter)
			if file_size and tonumber(cached_size) ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] ClamAV cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, tonumber(cached_size)))
				return false, nil, nil
			end
			-- Verify TTL hasn't expired (defensive check in addition to cachestore auto-expiration)
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] ClamAV cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug(string.format(
					"[CACHE] ClamAV cache entry invalidated by cleanup marker - treating as MISS"))
				-- Delete the invalidated entry
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[CACHE] ClamAV local cache HIT for checksum: %s (size: %s bytes, age: %ds, TTL remaining: %ds)",
				checksum:sub(1, 16) .. "...", cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end
	plugin:log_debug("[CACHE] ClamAV local cache MISS for checksum: " .. checksum:sub(1, 16) .. "...")
	return false, nil, nil
end

-- Add ClamAV scan result to local cache (by SHA256 checksum).
-- Stores: result, file size, and timestamp for verification and debugging.
-- Cache format: "result|size|timestamp"
-- Returns success boolean and error message if failed.
function cache.add_to_clamav_cache(plugin, checksum, value, file_size)
	local cache_key = "plugin_malware_scan_clamav_" .. checksum
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- Uses configurable TTL: MALWARE_SCAN_CACHE_CLEAN_TTL and MALWARE_SCAN_CACHE_VIRUS_TTL
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
	end

	-- Store structured data: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())

	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		return false, err
	end
	plugin:log_debug(string.format("[CACHE] Added ClamAV result to cache: %s = %s (size: %d bytes, TTL: %ds)",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))
	return true
end

-- Check if VirusTotal scan result is in local cache.
-- Returns success boolean, cached result, and file size (for verification).
-- Cache format: "result|size|timestamp"
-- Note: Redis lookup is handled by get_composite_redis_cache() for performance.
function cache.is_in_vt_cache(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_virustotal_" .. checksum

	plugin:log_debug(string.format("[CACHE] is_in_vt_cache: checksum=%s", checksum:sub(1, 16) .. "..."))

	-- Check local cache (fast, ~1ms)
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|size|timestamp"
		local result, cached_size, timestamp = data:match("^([^|]+)|([^|]+)|([^|]+)$")
		if result then
			-- Verify file size matches
			if file_size and tonumber(cached_size) ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] VirusTotal cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, tonumber(cached_size)))
				return false, nil, nil
			end
			-- Verify TTL hasn't expired
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] VirusTotal cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug("[CACHE] VirusTotal cache entry invalidated by cleanup marker - treating as MISS")
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[CACHE] VirusTotal local cache HIT (size: %s bytes, age: %ds, TTL remaining: %ds)",
				cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end

	plugin:log_debug("[CACHE] VirusTotal local cache MISS")
	return false, nil, nil
end

-- Add VirusTotal scan result to local cache.
-- Stores: result, file size, and timestamp for verification and debugging.
-- Cache format: "result|size|timestamp"
-- Returns success boolean and error message if failed.
-- Note: Redis storage is handled by set_composite_redis_cache() for performance.
function cache.add_to_vt_cache(plugin, checksum, value, file_size)
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- This prevents false negatives if a file becomes identified as malware shortly after upload
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		plugin.logger:log(ERR, "[CACHE_CLEAN] VirusTotal result cached for " .. cache_ttl .. " seconds")
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		plugin.logger:log(ERR, "[CACHE_MALWARE] VirusTotal result cached for " .. cache_ttl .. " seconds")
	end

	local cache_key = "plugin_malware_scan_virustotal_" .. checksum

	plugin:log_debug(string.format("[CACHE] add_to_vt_cache: checksum=%s, value=%s, size=%d bytes, ttl=%ds",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))

	-- Store in local cache with structured format: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		plugin:log_debug("[CACHE] Failed to store VirusTotal in local cache: " .. tostring(err))
		return false, err
	end
	plugin:log_debug(string.format("[CACHE] VirusTotal result stored in local cache (size: %d bytes)", file_size or 0))

	return true
end

-- Check if ThreatFox result is in local cache.
-- Cache format: "result|size|timestamp"
-- Returns success boolean, cached result, and file size (or nil values if not found).
function cache.is_in_threatfox_cache(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_threatfox_" .. checksum

	plugin:log_debug(string.format("[CACHE] is_in_threatfox_cache: checksum=%s, file_size=%d",
		checksum:sub(1, 16) .. "...", file_size or 0))

	-- Check local cache (fast, ~1ms)
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|size|timestamp"
		local result, cached_size, timestamp = data:match("^([^|]+)|([^|]+)|([^|]+)$")
		if result then
			-- Verify file size matches to prevent collisions (same size can have different SHA256)
			if file_size and tonumber(cached_size) ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] ThreatFox cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, tonumber(cached_size)))
				return false, nil, nil
			end

			-- Verify TTL hasn't expired
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] ThreatFox cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug("[CACHE] ThreatFox cache entry invalidated by cleanup marker - treating as MISS")
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[CACHE] ThreatFox local cache HIT (size: %s bytes, age: %ds, TTL remaining: %ds)",
				cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end

	plugin:log_debug("[CACHE] ThreatFox local cache MISS")
	return false, nil, nil
end

-- Add ThreatFox result to local cache.
-- Cache format: "result|size|timestamp"
-- Returns success boolean and error message if failed.
-- Note: Redis storage is handled by set_composite_redis_cache() for performance.
function cache.add_to_threatfox_cache(plugin, checksum, value, file_size)
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- This prevents false negatives if a file becomes identified as malware shortly after upload
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		plugin.logger:log(ERR, "[CACHE_CLEAN] ThreatFox result cached for " .. cache_ttl .. " seconds")
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		plugin.logger:log(ERR, "[CACHE_MALWARE] ThreatFox result cached for " .. cache_ttl .. " seconds")
	end

	local cache_key = "plugin_malware_scan_threatfox_" .. checksum

	plugin:log_debug(string.format("[CACHE] add_to_threatfox_cache: checksum=%s, value=%s, size=%d bytes, ttl=%ds",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))

	-- Store in local cache with structured format: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		plugin:log_debug("[CACHE] Failed to store ThreatFox in local cache: " .. tostring(err))
		return false, err
	end
	plugin:log_debug(string.format("[CACHE] ThreatFox result stored in local cache (size: %d bytes)", file_size or 0))

	return true
end

-- Check if SentinelOne result is in local cache.
-- Cache format: "result|size|timestamp"
-- Returns success boolean, cached result, and file size (or nil values if not found).
function cache.is_in_sentinelone_cache(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_sentinelone_" .. checksum

	plugin:log_debug(string.format("[CACHE] is_in_sentinelone_cache: checksum=%s, file_size=%d",
		checksum:sub(1, 16) .. "...", file_size or 0))

	-- Check local cache (fast, ~1ms)
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|size|timestamp"
		local result, cached_size, timestamp = data:match("^([^|]+)|([^|]+)|([^|]+)$")
		if result then
			-- Verify file size matches to prevent collisions (same size can have different SHA256)
			if file_size and tonumber(cached_size) ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] SentinelOne cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, tonumber(cached_size)))
				return false, nil, nil
			end

			-- Verify TTL hasn't expired
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] SentinelOne cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug("[CACHE] SentinelOne cache entry invalidated by cleanup marker - treating as MISS")
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[CACHE] SentinelOne local cache HIT (size: %s bytes, age: %ds, TTL remaining: %ds)",
				cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end

	plugin:log_debug("[CACHE] SentinelOne local cache MISS")
	return false, nil, nil
end

-- Add SentinelOne result to local cache.
-- Cache format: "result|size|timestamp"
-- Returns success boolean and error message if failed.
-- Note: Redis storage is handled by set_composite_redis_cache() for performance.
function cache.add_to_sentinelone_cache(plugin, checksum, value, file_size)
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- This prevents false negatives if a file becomes identified as malware shortly after upload
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		plugin.logger:log(ERR, "[CACHE_CLEAN] SentinelOne result cached for " .. cache_ttl .. " seconds")
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		plugin.logger:log(ERR, "[CACHE_MALWARE] SentinelOne result cached for " .. cache_ttl .. " seconds")
	end

	local cache_key = "plugin_malware_scan_sentinelone_" .. checksum

	plugin:log_debug(string.format("[CACHE] add_to_sentinelone_cache: checksum=%s, value=%s, size=%d bytes, ttl=%ds",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))

	-- Store in local cache with structured format: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		plugin:log_debug("[CACHE] Failed to store SentinelOne in local cache: " .. tostring(err))
		return false, err
	end
	plugin:log_debug(string.format("[CACHE] SentinelOne result stored in local cache (size: %d bytes)", file_size or 0))

	return true
end

-- ============================================================================
-- CACHE CLEANUP ON RESTART
-- ============================================================================

-- Check if a cache entry should be invalidated based on cleanup marker.
-- Returns true if entry is older than cleanup marker (should be invalidated).
function cache.should_invalidate_on_cleanup(plugin, entry_timestamp)
	local marker_key = "plugin_malware_scan_cleanup_marker"
	local ok, marker_value = plugin.cachestore:get(marker_key)

	if not ok or not marker_value then
		-- No cleanup marker exists, entry is valid
		return false
	end

	local cleanup_timestamp = tonumber(marker_value)
	if not cleanup_timestamp then
		-- Invalid marker format, treat entry as valid
		return false
	end

	-- Entry is older than cleanup marker, should be invalidated
	return entry_timestamp < cleanup_timestamp
end

-- Try to acquire distributed lock for cache cleanup.
-- Uses cachestore to ensure only one worker performs cleanup.
-- Returns true if lock was acquired, false if another worker has it.
--
-- NOTE: Uses atomic add() operation to prevent TOCTOU race condition (CWE-362).
-- If cachestore doesn't support add(), falls back to get+set (with race condition risk).
function cache.try_acquire_cleanup_lock(plugin)
	local lock_key = "plugin_malware_scan_cleanup_lock"
	local lock_ttl = 60  -- Lock expires after 60 seconds (safety timeout)

	-- Try atomic add() first (only succeeds if key doesn't exist)
	if plugin.cachestore.add then
		local add_ok, add_err = plugin.cachestore:add(lock_key, os.time(), lock_ttl)
		if add_ok then
			plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Distributed lock acquired successfully (atomic)")
			return true
		else
			-- Lock already exists or add() failed
			plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Lock already held by another worker")
			return false
		end
	end

	-- Fallback to get+set (has TOCTOU race condition, but better than nothing)
	plugin.logger:log(WARN, "[CACHE_CLEANUP] cachestore doesn't support add(), using non-atomic fallback")

	local ok, err = plugin.cachestore:get(lock_key)
	if ok then
		-- Lock already exists
		plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Lock already held by another worker")
		return false
	end

	-- Lock doesn't exist, try to acquire it (race window here!)
	local set_ok, set_err = plugin.cachestore:set(lock_key, os.time(), lock_ttl)
	if not set_ok then
		plugin.logger:log(WARN, "[CACHE_CLEANUP] Failed to acquire lock: " .. tostring(set_err))
		return false
	end

	plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Distributed lock acquired successfully (non-atomic)")
	return true
end

-- Release distributed lock for cache cleanup.
-- Removes the lock from cachestore to allow future cleanups.
function cache.release_cleanup_lock(plugin)
	local lock_key = "plugin_malware_scan_cleanup_lock"

	-- Delete the lock key
	local ok, err = plugin.cachestore:delete(lock_key)
	if not ok then
		plugin.logger:log(WARN, "[CACHE_CLEANUP] Failed to release lock: " .. tostring(err))
		return false
	end

	plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Distributed lock released")
	return true
end

-- Clear all cached scan results on plugin restart.
-- Clears both local cache (cachestore) and Redis cache (clusterstore).
-- Uses marker-based approach for local cache (lazy invalidation).
-- Uses SCAN + UNLINK for Redis cache (pattern-based deletion).
-- This is useful after ClamAV signature updates or to resolve cache corruption.
-- Returns success boolean and statistics about cleanup.
function cache.cleanup_all_caches(plugin)
	local stats = {
		local_cleared = 0,
		redis_cleared = 0,
		errors = 0
	}

	plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Starting cache cleanup on restart")

	-- Clear local cache by setting cleanup marker timestamp
	-- BunkerWeb's cachestore doesn't have enumerate/flush methods,
	-- so we use a marker-based approach: set current timestamp as cleanup marker
	-- On subsequent cache lookups, entries older than this marker are treated as expired
	local cleanup_marker_key = "plugin_malware_scan_cleanup_marker"
	local cleanup_timestamp = os.time()
	local marker_ttl = 86400 * 7  -- Keep marker for 7 days (max cache TTL)

	local marker_ok, marker_err = plugin.cachestore:set(cleanup_marker_key, tostring(cleanup_timestamp), marker_ttl)
	if marker_ok then
		plugin.logger:log(NOTICE, string.format(
			"[CACHE_CLEANUP] Local cache cleanup marker set (timestamp: %d). Old entries will be invalidated on next lookup.",
			cleanup_timestamp
		))
		stats.local_cleared = 1
	else
		plugin.logger:log(WARN, "[CACHE_CLEANUP] Failed to set local cache cleanup marker: " .. tostring(marker_err))
		stats.errors = stats.errors + 1
	end

	-- Clear Redis cache if shared database is enabled
	local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
	local use_redis = plugin.ctx.bw.use_redis == "yes"

	if use_shared and use_redis then
		-- Check if circuit breaker is open
		if cache.should_skip_redis(plugin) then
			plugin.logger:log(WARN, "[CACHE_CLEANUP] Redis circuit breaker open, skipping Redis cleanup")
			return true, stats
		end

		plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Clearing Redis shared cache using SCAN + UNLINK")

		-- Connect to Redis
		local connect_ok, connect_err = plugin.clusterstore:connect()
		if not connect_ok then
			plugin.logger:log(WARN, "[CACHE_CLEANUP] Failed to connect to Redis: " .. tostring(connect_err))
			stats.errors = stats.errors + 1
			cache.record_redis_failure(plugin)
			return true, stats
		end

		-- Clear plugin-related keys from Redis using SCAN + UNLINK
		-- UNLINK is non-blocking (async deletion), better than DEL
		-- Support granular cleanup: only clean patterns where flag is enabled
		local cleanup_all = plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_ALL"] == "yes"

		-- Build pattern list based on enabled flags
		local redis_patterns = {}

		-- Check each scanner's cleanup flag (or cleanup_all master switch)
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_CLAMAV"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_clamav_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_VIRUSTOTAL"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_virustotal_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_THREATFOX"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_threatfox_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_SENTINELONE"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_sentinelone_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_ATTACKER_IPV4"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_attacker_ipv4_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_ATTACKER_IPV6"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_attacker_ipv6_*")
		end

		-- Always clean composite results cache if any scanner is being cleaned
		if #redis_patterns > 0 then
			table.insert(redis_patterns, "plugin_malware_scan_results_*")
		end

		-- If no patterns to clean, skip Redis cleanup
		if #redis_patterns == 0 then
			plugin.logger:log(NOTICE, "[CACHE_CLEANUP] No Redis cache cleanup flags enabled, skipping Redis cleanup")
			plugin.clusterstore:close()
			return true, stats
		end

		-- Safety validation: verify all patterns have expected prefix
		local SAFE_PREFIX = "plugin_malware_scan_"
		for _, pattern in ipairs(redis_patterns) do
			if not pattern:match("^" .. SAFE_PREFIX) then
				plugin.logger:log(ERR, string.format(
					"[CACHE_CLEANUP] SAFETY ERROR: Pattern '%s' does not start with expected prefix '%s' - ABORTING cleanup",
					pattern,
					SAFE_PREFIX
				))
				plugin.clusterstore:close()
				stats.errors = stats.errors + 1
				return false, stats
			end
		end

		plugin.logger:log(NOTICE, string.format(
			"[CACHE_CLEANUP] Cleaning %d Redis cache pattern(s): %s",
			#redis_patterns,
			table.concat(redis_patterns, ", ")
		))

		local total_keys_deleted = 0

		for _, pattern in ipairs(redis_patterns) do
			local cursor = "0"
			local keys_for_pattern = 0

			repeat
				-- SCAN returns: cursor, array of keys
				-- SCAN 0 MATCH pattern COUNT 100
				local scan_result, scan_err = plugin.clusterstore:call("scan", cursor, "MATCH", pattern, "COUNT", 100)

				if not scan_result then
					plugin.logger:log(WARN, "[CACHE_CLEANUP] Redis SCAN failed for pattern " .. pattern .. ": " .. tostring(scan_err))
					stats.errors = stats.errors + 1
					cache.record_redis_failure(plugin)
					break
				end

				-- scan_result is a table: {new_cursor, {key1, key2, ...}}
				-- Validate scan_result structure to prevent nil dereference
				if type(scan_result) ~= "table" or #scan_result < 2 then
					plugin.logger:log(WARN, "[CACHE_CLEANUP] Invalid Redis SCAN result format")
					stats.errors = stats.errors + 1
					break
				end

				cursor = scan_result[1]
				local keys = scan_result[2]

				-- Delete keys using UNLINK (non-blocking)
				if keys and #keys > 0 then
					-- Safety validation: verify each key has expected prefix before deletion
					local SAFE_PREFIX = "plugin_malware_scan_"
					local validated_keys = {}
					for _, key in ipairs(keys) do
						if key:match("^" .. SAFE_PREFIX) then
							table.insert(validated_keys, key)
						else
							plugin.logger:log(WARN, string.format(
								"[CACHE_CLEANUP] SAFETY WARNING: Skipping key '%s' - does not match expected prefix '%s'",
								key,
								SAFE_PREFIX
							))
							stats.errors = stats.errors + 1
						end
					end

					-- Only unlink validated keys
					if #validated_keys > 0 then
						local unlink_result, unlink_err = plugin.clusterstore:call("unlink", unpack(validated_keys))
						if unlink_result then
							keys_for_pattern = keys_for_pattern + tonumber(unlink_result)
							cache.record_redis_success(plugin)
						else
							plugin.logger:log(WARN, "[CACHE_CLEANUP] Redis UNLINK failed: " .. tostring(unlink_err))
							stats.errors = stats.errors + 1
							cache.record_redis_failure(plugin)
						end
					end
				end

			until cursor == "0"

			if keys_for_pattern > 0 then
				plugin.logger:log(NOTICE, string.format(
					"[CACHE_CLEANUP] Deleted %d keys matching pattern: %s",
					keys_for_pattern,
					pattern
				))
				total_keys_deleted = total_keys_deleted + keys_for_pattern
			end
		end

		-- Close Redis connection
		plugin.clusterstore:close()

		stats.redis_cleared = total_keys_deleted
		plugin.logger:log(NOTICE, string.format(
			"[CACHE_CLEANUP] Redis cleanup complete - deleted %d keys total",
			total_keys_deleted
		))
	else
		plugin.logger:log(NOTICE, "[CACHE_CLEANUP] Redis shared cache disabled, skipping Redis cleanup")
	end

	plugin.logger:log(NOTICE, string.format(
		"[CACHE_CLEANUP] Cleanup complete - local: marker set (%d), redis operations: %d, errors: %d",
		stats.local_cleared,
		stats.redis_cleared,
		stats.errors
	))

	return true, stats
end

-- Return module
return cache
