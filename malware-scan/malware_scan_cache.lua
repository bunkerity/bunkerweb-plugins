-- BunkerWeb Malware Scan - Cache Module
-- Handles all caching operations including local cache and Redis/Valkey shared cache
-- Includes circuit breaker, composite cache, attacker tracking, and differential TTL

local cjson = require("cjson")
local utils = require("bunkerweb.utils")
local logger = require("malware_scan_logger")
local ms_utils = require("malware_scan_utils")
local database = require("malware_scan_database")
local lfs = require("lfs")

-- Load metrics module (optional - gracefully handles if not available)
local metrics_ok, metrics = pcall(require, "malware_scan_metrics")
if not metrics_ok then
	metrics = nil  -- Metrics not available
end

local ngx = ngx
local tonumber = tonumber
local tostring = tostring

-- Module table
local cache = {}

-- Module version
cache.VERSION = "0.8.0"

-- ============================================================================
-- TYPE ALIASES (for documentation and LuaLS type checking)
-- ============================================================================

---@alias Scanner string Scanner name (e.g., "virustotal", "sentinelone", "malwarebazaar")
---@alias Number number Numeric value
---@alias Timestamp number Unix timestamp in seconds
---@alias Error string Error message or type

-- ============================================================================
-- HELPER FUNCTIONS
-- ============================================================================

--- Remove directory recursively (like rm -rf)
--- @param path string Directory path to remove
--- @return boolean success True if removal succeeded, false otherwise
local function remove_directory_recursive(path)
	if not path or path == "" then
		return false
	end

	-- Check if directory exists
	local attr = lfs.attributes(path, "mode")
	if not attr then
		return true  -- Already doesn't exist
	end

	if attr ~= "directory" then
		-- It's a file, just remove it
		return os.remove(path) ~= nil
	end

	-- Recursively remove directory contents
	for entry in lfs.dir(path) do
		if entry ~= "." and entry ~= ".." then
			local entry_path = path .. "/" .. entry
			local entry_attr = lfs.attributes(entry_path, "mode")

			if entry_attr == "directory" then
				-- Recursively remove subdirectory
				remove_directory_recursive(entry_path)
			else
				-- Remove file
				os.remove(entry_path)
			end
		end
	end

	-- Remove the now-empty directory
	return lfs.rmdir(path) ~= nil
end


-- ============================================================================
-- API ERROR CIRCUIT BREAKER FUNCTIONS
-- Protects against API failures (user_blacklisted, rate limits, etc.) with exponential backoff
-- Prevents repeated failed API calls that waste resources and may lead to permanent blocks
-- ============================================================================

-- Get API error circuit breaker state from local cache.
-- Returns failure_count, last_failure_time, and error_type.
--- @param plugin Plugin instance
--- @param scanner Scanner name (e.g., "malwarebazaar", "sentinelone")
--- @return number failure_count
--- @return number last_failure_time
--- @return string|nil error_type
function cache.api_error_get(plugin, scanner)
	local cb_key = "plugin_malware_scan_api_error_" .. scanner
	local ok, data = plugin.cachestore:get(cb_key)
	if not ok or not data then
		return 0, 0, nil  -- No errors recorded
	end

	-- Data format: "failure_count:last_failure_time:error_type"
	local count, time, error_type = data:match("^(%d+):(%d+):(.+)$")
	if not count or not time then
		return 0, 0, nil
	end

	return tonumber(count) or 0, tonumber(time) or 0, error_type
end

-- Update API error circuit breaker state in local cache and Redis.
-- Stores failure count, timestamp, and error type for later retry logic.
--- @param plugin Plugin instance
--- @param scanner Scanner name (e.g., "malwarebazaar", "sentinelone")
--- @param failure_count Number of consecutive failures
--- @param last_failure_time Timestamp of last failure
--- @param error_type Error type (e.g., "user_blacklisted", "no_api_key", "rate_limit")
function cache.api_error_set(plugin, scanner, failure_count, last_failure_time, error_type)
	-- Validate numeric inputs to prevent corruption (Medium severity issue #11)
	failure_count = tonumber(failure_count) or 0
	last_failure_time = tonumber(last_failure_time) or 0

	-- Bounds checking: prevent negative values and excessive counts
	if failure_count < 0 or failure_count > 1000000 then
		logger.log_warn("[CACHE] Invalid API error failure_count (" .. tostring(failure_count) .. "), resetting to 0")
		failure_count = 0
	end

	if last_failure_time < 0 then
		logger.log_warn("[CACHE] Invalid API error last_failure_time (" .. tostring(last_failure_time) .. "), resetting to 0")
		last_failure_time = 0
	end

	local cb_key = "plugin_malware_scan_api_error_" .. scanner
	local data = tostring(failure_count) .. ":" .. tostring(last_failure_time) .. ":" .. tostring(error_type)

	-- Calculate TTL based on exponential backoff (1 min to 24 hours)
	local backoff_seconds = cache.api_error_backoff_calculate(failure_count)
	-- Add 60 seconds buffer to TTL to ensure data persists through backoff period
	local ttl = backoff_seconds + 60

	-- Store in local cache
	plugin.cachestore:set(cb_key, data, ttl)

	-- Also store in Redis for cluster-wide awareness
	if database.is_enabled(plugin) then
		local redis_key = "plugin_malware_scan_api_error_" .. scanner
		database.set(plugin, redis_key, data, ttl)
	end
end

-- Calculate exponential backoff delay for API errors.
-- Starts at 1 minute (60s), doubles each time, up to maximum of 24 hours (86400s).
-- Formula: min(60 * 2^failure_count, 86400)
--- @param failure_count Number of consecutive failures
--- @return number backoff_seconds Backoff delay in seconds
function cache.api_error_backoff_calculate(failure_count)
	-- Cap failure_count to prevent integer overflow (2^20 = ~1 million seconds = 12 days)
	local capped_count = math.min(failure_count, 20)
	-- Start at 60 seconds (1 minute), max 86400 seconds (24 hours)
	return math.min(60 * (2 ^ capped_count), 86400)
end

-- Check if API should be skipped based on error circuit breaker state.
-- Returns true if API should be skipped (still in backoff), false if retry is allowed.
-- Also checks Redis for cluster-wide error state.
--- @param plugin Plugin instance
--- @param scanner Scanner name (e.g., "malwarebazaar", "sentinelone")
--- @return boolean should_skip True if API should be skipped
--- @return string|nil error_type Error type or nil
--- @return number remaining_backoff Remaining backoff time in seconds
function cache.api_error_should_skip(plugin, scanner)
	-- Check local cache first
	local failure_count, last_failure_time, error_type = cache.api_error_get(plugin, scanner)

	-- Check Redis for cluster-wide errors (another worker may have recorded failure)
	if database.is_enabled(plugin) and failure_count == 0 then
		local redis_key = "plugin_malware_scan_api_error_" .. scanner
		local ok, redis_data, err = database.get(plugin, redis_key)
		if ok and redis_data then
			-- Parse Redis data
			local r_count, r_time, r_error = redis_data:match("^(%d+):(%d+):(.+)$")
			if r_count and r_time then
				failure_count = tonumber(r_count) or 0
				last_failure_time = tonumber(r_time) or 0
				error_type = r_error
				-- Store in local cache for faster subsequent checks
				cache.api_error_set(plugin, scanner, failure_count, last_failure_time, error_type)
			end
		end
	end

	if failure_count == 0 then
		return false, nil, 0  -- No errors, allow API call
	end

	local now = ngx.time()
	local backoff_seconds = cache.api_error_backoff_calculate(failure_count)
	local time_since_failure = now - last_failure_time

	if time_since_failure >= backoff_seconds then
		return false, error_type, 0  -- Backoff period expired, allow retry
	end

	-- Still in backoff period
	local remaining = backoff_seconds - time_since_failure
	plugin:log_debug(string.format(
		"[API_ERROR] Skipping %s API (circuit breaker): error=%s, failures=%d, backoff=%ds, remaining=%ds",
		scanner, error_type or "unknown", failure_count, backoff_seconds, remaining
	))
	return true, error_type, remaining
end

-- Record a successful API operation (resets error circuit breaker).
--- @param plugin Plugin instance
--- @param scanner Scanner name
function cache.api_error_success(plugin, scanner)
	local cb_key = "plugin_malware_scan_api_error_" .. scanner
	plugin.cachestore:delete(cb_key)

	-- Also delete from Redis
	if database.is_enabled(plugin) then
		local redis_key = "plugin_malware_scan_api_error_" .. scanner
		database.delete(plugin, redis_key)
	end

	plugin:log_debug("[v" .. cache.VERSION .. "] [API_ERROR] " .. scanner .. " API operation successful, circuit breaker reset")
end

-- Record a failed API operation (increments error circuit breaker).
--- @param plugin Plugin instance
--- @param scanner Scanner name
--- @param error_type Error type (e.g., "user_blacklisted", "no_api_key", "rate_limit")
function cache.api_error_failure(plugin, scanner, error_type)
	local failure_count = cache.api_error_get(plugin, scanner)
	local now = ngx.time()
	failure_count = failure_count + 1

	cache.api_error_set(plugin, scanner, failure_count, now, error_type)

	local backoff_seconds = cache.api_error_backoff_calculate(failure_count)

	-- Format backoff time in human-readable format
	local backoff_str
	if backoff_seconds < 60 then
		backoff_str = tostring(backoff_seconds) .. "s"
	elseif backoff_seconds < 3600 then
		backoff_str = string.format("%.1fm", backoff_seconds / 60)
	else
		backoff_str = string.format("%.1fh", backoff_seconds / 3600)
	end

	logger.log_error( string.format(
		"[API_ERROR] %s API failure #%d (error=%s), backing off for %s",
		scanner, failure_count, error_type, backoff_str
	))
end

-- ============================================================================
-- COMPOSITE REDIS CACHE FUNCTIONS
-- Single lookup/write for all scanner results (performance optimization)
-- ============================================================================

--- Get composite scan results from Redis (all scanners in one lookup).
--- Returns success boolean, results table (or nil), and error message.
--- Results table format: {vt="result", sentinelone="result"}
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @return boolean success True if operation succeeded
--- @return table|nil results Results table or nil if not found
--- @return string|nil error Error message if failed
function cache.redis_composite_get(plugin, checksum)
	local cache_key = "plugin_malware_scan_results_" .. checksum
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_SHARED] Attempting composite Redis lookup for %s...", checksum:sub(1, 16) .. "..."))

	local ok, data, err = database.get(plugin, cache_key)
	if not ok then
		return false, nil, err or "redis lookup failed"
	end

	if not data then
		-- Cache miss (not an error)
		return true, nil, nil
	end

	-- Parse JSON
	local decode_ok, results = pcall(cjson.decode, data)
	if not decode_ok then
		logger.log_error( "[CACHE_SHARED] Failed to parse composite cache JSON: " .. tostring(results))
		return false, nil, "json parse error"
	end

	-- Validate JSON decoded to expected data structure (Medium severity issue #11)
	if type(results) ~= "table" then
		logger.log_error( "[CACHE_SHARED] Invalid data type after JSON decode: " .. type(results))
		return false, nil, "invalid data structure"
	end

	local count = (results.vt and 1 or 0) + (results.sentinelone and 1 or 0)
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_SHARED] Composite cache HIT (%d scanner results)", count))
	return true, results, nil
end

--- Store composite scan results in Redis (all scanners in one write).
--- Takes checksum and results table: {vt="result", sentinelone="result"}
--- Returns success boolean and error message.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param results table Results table with scanner names as keys
--- @return boolean success True if operation succeeded
--- @return string|nil error Error message if failed
function cache.redis_composite_set(plugin, checksum, results)
	local cache_key = "plugin_malware_scan_results_" .. checksum
	local shared_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_SHARED_TTL"]) or 21600

	-- Encode as JSON
	local encode_ok, json_data = pcall(cjson.encode, results)
	if not encode_ok then
		logger.log_error( "[CACHE_SHARED] Failed to encode composite cache JSON: " .. tostring(json_data))
		return false, "json encode error"
	end

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_SHARED] Storing composite results in Redis (TTL=%ds)...", shared_ttl))

	local ok, err = database.set(plugin, cache_key, json_data, shared_ttl)
	if not ok then
		logger.log_error( "[CACHE_SHARED] Failed to store composite results in Redis: " .. tostring(err))
		return false, err
	end

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_SHARED] Composite results stored in Redis (TTL=%ds)", shared_ttl))
	return true, nil
end

-- ============================================================================
-- ATTACKER IP TRACKING
-- Tracks IPs that upload malware, with separate IPv4/IPv6 namespaces
-- ============================================================================

--- Detect if an IP address is IPv4 or IPv6.
--- Returns "ipv4" or "ipv6"
--- @param ip string IP address to check
--- @return string version "ipv4" or "ipv6"
function cache.ip_detect_version(ip)
	-- IPv6 addresses contain colons
	if ip:match(":") then
		return "ipv6"
	else
		return "ipv4"
	end
end

--- Track attacker IP that uploaded malware.
--- Stores IP address, timestamp of last upload, and array of SHA256 checksums.
--- Data is stored in local cache and optionally in Redis when shared cache is enabled.
--- IPv4 and IPv6 addresses are stored in separate key namespaces for better organization.
--- @param plugin Plugin instance
--- @param client_ip string Client IP address
--- @param checksum string SHA256 checksum of malware
--- @return boolean success True if tracking succeeded
function cache.attacker_track(plugin, client_ip, checksum)
	local track_enabled = plugin.variables["MALWARE_SCAN_TRACK_ATTACKERS"] == "yes"
	if not track_enabled then
		return true  -- Feature disabled, not an error
	end

	local attacker_ttl = tonumber(plugin.variables["MALWARE_SCAN_TRACK_ATTACKER_TTL"]) or 7776000  -- 90 days default

	-- Separate IPv4 and IPv6 into different key namespaces
	local ip_version = cache.ip_detect_version(client_ip)
	local cache_key = "plugin_malware_scan_attacker_" .. ip_version .. "_" .. client_ip

	-- Get existing attacker data from local cache
	local existing_data = nil
	local ok, cached = plugin.cachestore:get(cache_key)
	if ok and cached then
		local decode_ok, decoded = pcall(cjson.decode, cached)
		if decode_ok then
			existing_data = decoded
		end
	end

	-- If not in local cache, try Redis (if shared cache enabled)
	if not existing_data and database.is_enabled(plugin) then
		local redis_ok, redis_data = database.get(plugin, cache_key)
		if redis_ok and redis_data then
			local decode_ok, decoded = pcall(cjson.decode, redis_data)
			if decode_ok then
				existing_data = decoded
			end
		end
	end

	-- Create or update attacker data
	local current_time = os.time()
	local attacker_data = existing_data or {
		first_upload = current_time,
		last_upload = current_time,
		checksums = {},
		upload_count = 0
	}

	-- Update last upload timestamp (preserves first_upload from existing data)
	attacker_data.last_upload = current_time

	-- Ensure first_upload exists (backwards compatibility for old cache entries)
	if not attacker_data.first_upload then
		attacker_data.first_upload = current_time
	end

	-- Add checksum if not already present (avoid duplicates)
	local checksum_exists = false
	for _, existing_checksum in ipairs(attacker_data.checksums) do
		if existing_checksum == checksum then
			checksum_exists = true
			break
		end
	end

	if not checksum_exists then
		table.insert(attacker_data.checksums, checksum)
		attacker_data.upload_count = attacker_data.upload_count + 1
	end

	-- Encode as JSON
	local encode_ok, json_data = pcall(cjson.encode, attacker_data)
	if not encode_ok then
		logger.log_error( "[ATTACKER_TRACK] Failed to encode attacker data: " .. tostring(json_data))
		return false
	end

	-- Store in local cache
	local store_ok, store_err = plugin.cachestore:set(cache_key, json_data, attacker_ttl)
	if not store_ok then
		logger.log_error( "[ATTACKER_TRACK] Failed to store in local cache: " .. tostring(store_err))
	end

	-- Store in Redis if shared cache enabled
	if database.is_enabled(plugin) then
		local redis_ok, redis_err = database.set(plugin, cache_key, json_data, attacker_ttl)
		if redis_ok then
			logger.log_notice( string.format("[v" .. cache.VERSION .. "] [ATTACKER_TRACK] %s %s tracked: %d unique malware uploads (TTL=%ds, stored in Redis)",
				ip_version:upper(), client_ip, attacker_data.upload_count, attacker_ttl))
		else
			logger.log_error( "[ATTACKER_TRACK] Failed to store in Redis: " .. tostring(redis_err))
		end
	else
		logger.log_notice( string.format("[v" .. cache.VERSION .. "] [ATTACKER_TRACK] %s %s tracked: %d unique malware uploads (TTL=%ds, local only)",
			ip_version:upper(), client_ip, attacker_data.upload_count, attacker_ttl))
	end

	return true
end

--- Get attacker data for a specific IP.
--- Returns attacker data table or nil if not found.
--- Checks local cache first, then Redis if enabled.
--- IPv4 and IPv6 addresses are stored in separate key namespaces.
--- @param plugin Plugin instance
--- @param client_ip string Client IP address
--- @return table|nil attacker_data Attacker data or nil if not found
function cache.attacker_get(plugin, client_ip)
	local track_enabled = plugin.variables["MALWARE_SCAN_TRACK_ATTACKERS"] == "yes"
	if not track_enabled then
		return nil  -- Feature disabled
	end

	-- Separate IPv4 and IPv6 into different key namespaces
	local ip_version = cache.ip_detect_version(client_ip)
	local cache_key = "plugin_malware_scan_attacker_" .. ip_version .. "_" .. client_ip

	-- Check local cache first
	local ok, cached = plugin.cachestore:get(cache_key)
	if ok and cached then
		local decode_ok, decoded = pcall(cjson.decode, cached)
		if decode_ok then
			return decoded
		end
	end

	-- Try Redis if shared cache enabled
	if database.is_enabled(plugin) then
		local redis_ok, redis_data = database.get(plugin, cache_key)
		if redis_ok and redis_data then
			local decode_ok, decoded = pcall(cjson.decode, redis_data)
			if decode_ok then
				-- Cache locally for faster subsequent lookups
				local ttl = tonumber(plugin.variables["MALWARE_SCAN_TRACK_ATTACKER_TTL"]) or 7776000  -- 90 days default
				plugin.cachestore:set(cache_key, redis_data, ttl)
				return decoded
			end
		end
	end

	return nil  -- Not found
end

-- ============================================================================
-- LOCAL CACHE FUNCTIONS
-- Fast local cache operations with differential TTL for clean/malicious files
-- ============================================================================

--- Check if file scan result is in local cache.
--- Returns success boolean and cached value or nil.
--- @param plugin Plugin instance
--- @param file_path string File path to check
--- @return boolean success True if operation succeeded
--- @return string|nil value Cached value or nil
function cache.cache_check(plugin, file_path)
	local ok, data = plugin.cachestore:get("plugin_malware_scan_file_" .. file_path)
	if not ok then
		return false, nil
	end
	return true, data
end

--- Add scan result to local cache.
--- Returns success boolean and error message if failed.
--- @param plugin Plugin instance
--- @param file_path string File path
--- @param value string Scan result value
--- @return boolean success True if operation succeeded
--- @return string|nil error Error message if failed
function cache.cache_add(plugin, file_path, value)
	local ok, err = plugin.cachestore:set(
		"plugin_malware_scan_file_" .. file_path,
		value,
		3600
	)
	if not ok then
		return false, err
	end
	return true
end

--- Check if ClamAV scan result is in local cache (by SHA256 checksum).
--- Returns success boolean, cached result, and file size (for verification).
--- Cache format: "result|size|timestamp" or "error|error_message|timestamp"
--- For errors, returns: true, "error", 0, error_message
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number|nil File size for verification
--- @return boolean success True if cache hit
--- @return string|nil result Cached result or nil
--- @return number|nil cached_size Cached file size or nil
--- @return string|nil error_msg Error message if result is "error"
function cache.clamav_check(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_clamav_" .. checksum
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|data|timestamp" (data = size for results, error_msg for errors)
		local result, cached_data, timestamp = data:match("^([^|]+)|([^|]*)|([^|]+)$")
		if result then
			-- Handle cached errors (negative caching)
			if result == "error" then
				local cache_age = os.time() - tonumber(timestamp)
				local error_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_ERROR_TTL"]) or 60
				if cache_age > error_ttl then
					plugin:log_debug(string.format(
						"[CACHE] ClamAV error cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
						cache_age, error_ttl))
					return false, nil, nil, nil
				end
				plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] ClamAV error cache HIT for checksum: %s (error: %s, age: %ds)",
					checksum:sub(1, 16) .. "...", cached_data or "unknown", cache_age))
				-- Return error: true (cache hit), "error" (result type), 0 (no size), error_message
				return true, "error", 0, cached_data or "unknown error"
			end

			-- Handle normal scan results
			local cached_size = tonumber(cached_data) or 0

			-- Verify file size matches (prevents collisions and provides quick filter)
			if file_size and cached_size ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] ClamAV cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, cached_size))
				return false, nil, nil, nil
			end
			-- Verify TTL hasn't expired (defensive check in addition to cachestore auto-expiration)
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] ClamAV cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug(string.format(
					"[CACHE] ClamAV cache entry invalidated by cleanup marker - treating as MISS"))
				-- Delete the invalidated entry
				plugin.cachestore:delete(cache_key)
				return false, nil, nil, nil
			end

			plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] ClamAV local cache HIT for checksum: %s (size: %s bytes, age: %ds, TTL remaining: %ds)",
				checksum:sub(1, 16) .. "...", cached_size, cache_age, ttl - cache_age))
			return true, result, cached_size, nil
		end
	end
	plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] ClamAV local cache MISS for checksum: " .. checksum:sub(1, 16) .. "...")
	-- Record cache miss metric
	if metrics then
		metrics.record_cache("clamav", false)
	end
	return false, nil, nil, nil
end

-- Add ClamAV scan result to local cache (by SHA256 checksum).
-- Stores: result, file size, and timestamp for verification and debugging.
-- Cache format: "result|size|timestamp" or "error|error_message|timestamp" for errors
-- Returns success boolean and error message if failed.
--- @param is_error boolean If true, value is treated as error message (negative caching)
function cache.clamav_add(plugin, checksum, value, file_size, is_error)
	local cache_key = "plugin_malware_scan_clamav_" .. checksum
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- Uses configurable TTL: MALWARE_SCAN_CACHE_CLEAN_TTL, MALWARE_SCAN_CACHE_VIRUS_TTL, MALWARE_SCAN_CACHE_ERROR_TTL
	local cache_ttl
	local cache_data

	if is_error then
		-- Negative caching: cache errors with short TTL to prevent repeated failed attempts
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_ERROR_TTL"]) or 60  -- Default 60 seconds for errors
		cache_data = string.format("error|%s|%d", value or "unknown error", os.time())
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] Added ClamAV error to cache: %s = %s (TTL: %ds)",
			checksum:sub(1, 16) .. "...", value or "unknown error", cache_ttl))
	elseif value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] Added ClamAV result to cache: %s = %s (size: %d bytes, TTL: %ds)",
			checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] Added ClamAV result to cache: %s = %s (size: %d bytes, TTL: %ds)",
			checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))
	end

	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		return false, err
	end
	return true
end

-- Try to acquire lock for ClamAV scan (atomic operation to prevent concurrent scans).
-- Uses cache's add() which only succeeds if key doesn't exist (atomic compare-and-set).
-- Returns: boolean lock_acquired
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @return boolean acquired True if lock acquired, false if another thread holds lock
function cache.clamav_try_lock(plugin, checksum)
	local lock_key = "plugin_malware_scan_clamav_lock_" .. checksum
	local lock_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_LOCK_TTL"]) or 60

	-- add() is atomic - only succeeds if key doesn't exist
	local ok, err = plugin.cachestore:add(lock_key, "scanning", lock_ttl)

	if ok then
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] Acquired lock for checksum: %s (TTL: %ds)",
			checksum:sub(1, 16) .. "...", lock_ttl))
		-- Record lock acquisition metric
		if metrics then
			metrics.record_lock_acquired("clamav")
		end
		return true
	else
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] Lock already held by another request: %s",
			checksum:sub(1, 16) .. "..."))
		return false
	end
end

-- Release lock for ClamAV scan.
-- Should be called after scan completes (success or failure) or before returning on error.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
function cache.clamav_release_lock(plugin, checksum)
	local lock_key = "plugin_malware_scan_clamav_lock_" .. checksum
	plugin.cachestore:delete(lock_key)
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] Released lock for checksum: %s",
		checksum:sub(1, 16) .. "..."))
end

-- Wait for another request to complete ClamAV scan and return the cached result.
-- Polls cache with exponential backoff until result appears or timeout occurs.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number File size for validation
--- @return boolean success
--- @return string|nil result
--- @return number|nil cached_size
--- @return string|nil error_msg
function cache.clamav_wait_for_result(plugin, checksum, file_size)
	local wait_timeout_ms = tonumber(plugin.variables["MALWARE_SCAN_CACHE_WAIT_TIMEOUT"]) or 30000
	local start_time = ngx.now() * 1000  -- Convert to milliseconds
	local wait_intervals = {10, 20, 50, 100, 200, 500}  -- Exponential backoff in ms
	local interval_index = 1
	local poll_count = 0

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] Waiting for scan result: %s (timeout: %dms)",
		checksum:sub(1, 16) .. "...", wait_timeout_ms))

	while true do
		poll_count = poll_count + 1

		-- Check if result is now available
		local cache_ok, result, cached_size, error_msg = cache.clamav_check(plugin, checksum, file_size)
		if cache_ok and result then
			-- Got result (clean, malicious, or error)
			plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] Scan result available after %d polls: %s = %s",
				poll_count, checksum:sub(1, 16) .. "...", result))
			return true, result, cached_size, error_msg
		end

		-- Check timeout
		local elapsed_ms = (ngx.now() * 1000) - start_time
		if elapsed_ms >= wait_timeout_ms then
			-- Timeout - fall back to scanning ourselves
			logger.log_warn( string.format(
				"[CACHE_LOCK] Timeout waiting for scan result after %dms (%d polls) - will scan independently",
				elapsed_ms, poll_count))
			return false, nil, nil, nil
		end

		-- Exponential backoff
		local wait_ms = wait_intervals[interval_index] or 500
		ngx.sleep(wait_ms / 1000)  -- Convert to seconds for ngx.sleep
		interval_index = math.min(interval_index + 1, #wait_intervals)
	end
end

--------------------------------------------------------------------------------
-- GENERIC LOCKING FUNCTIONS (reusable across all scanners)
--------------------------------------------------------------------------------

-- Generic wait function that works for all scanners.
-- Polls cache with exponential backoff until result appears or timeout occurs.
--- @param plugin Plugin instance
--- @param scanner_name string Scanner name ("clamav", "virustotal", "sentinelone")
--- @param checksum string SHA256 checksum
--- @param file_size number File size for validation
--- @return boolean success
--- @return any result Scanner-specific result
--- @return number|nil cached_size
--- @return string|nil error_msg For clamav only
local function cache_wait_for_result_generic(plugin, scanner_name, checksum, file_size)
	-- Map scanner names to their check functions
	local check_function_map = {
		clamav = cache.clamav_check,
		virustotal = cache.virustotal_check,
		sentinelone = cache.sentinelone_check
	}

	local check_function = check_function_map[scanner_name]
	if not check_function then
		logger.log_error( "[CACHE_LOCK] Unknown scanner: " .. scanner_name)
		return false, nil, nil, nil
	end

	local wait_timeout_ms = tonumber(plugin.variables["MALWARE_SCAN_CACHE_WAIT_TIMEOUT"]) or 30000
	local start_time = ngx.now() * 1000  -- Convert to milliseconds
	local wait_intervals = {10, 20, 50, 100, 200, 500}  -- Exponential backoff in ms
	local interval_index = 1
	local poll_count = 0

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [%s] Waiting for result: %s (timeout: %dms)",
		scanner_name:upper(), checksum:sub(1, 16) .. "...", wait_timeout_ms))

	while true do
		poll_count = poll_count + 1

		-- Check if result is now available (call scanner-specific check function)
		local cache_ok, result, cached_size, error_msg = check_function(plugin, checksum, file_size)
		if cache_ok and result then
			-- Got result (clean, malicious, or error)
			plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [%s] Result available after %d polls: %s = %s",
				scanner_name:upper(), poll_count, checksum:sub(1, 16) .. "...", result))
			return true, result, cached_size, error_msg
		end

		-- Check timeout
		local elapsed_ms = (ngx.now() * 1000) - start_time
		if elapsed_ms >= wait_timeout_ms then
			-- Timeout - fall back to scanning/querying independently
			logger.log_warn( string.format(
				"[CACHE_LOCK] [%s] Timeout waiting for result after %dms (%d polls) - will query independently",
				scanner_name:upper(), elapsed_ms, poll_count))
			return false, nil, nil, nil
		end

		-- Exponential backoff
		local wait_ms = wait_intervals[interval_index] or 500
		ngx.sleep(wait_ms / 1000)  -- Convert to seconds for ngx.sleep
		interval_index = math.min(interval_index + 1, #wait_intervals)
	end
end

--------------------------------------------------------------------------------
-- VIRUSTOTAL LOCKING FUNCTIONS
--------------------------------------------------------------------------------

-- Try to acquire lock for VirusTotal API query (atomic operation to prevent concurrent queries).
-- Uses cache's add() which only succeeds if key doesn't exist (atomic compare-and-set).
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @return boolean acquired True if lock acquired, false if another thread holds lock
function cache.virustotal_try_lock(plugin, checksum)
	local lock_key = "plugin_malware_scan_virustotal_lock_" .. checksum
	local lock_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_LOCK_TTL"]) or 60

	-- add() is atomic - only succeeds if key doesn't exist
	local ok, err = plugin.cachestore:add(lock_key, "scanning", lock_ttl)

	if ok then
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [VIRUSTOTAL] Acquired lock for checksum: %s (TTL: %ds)",
			checksum:sub(1, 16) .. "...", lock_ttl))
		return true
	else
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [VIRUSTOTAL] Lock already held by another request: %s",
			checksum:sub(1, 16) .. "..."))
		return false
	end
end

-- Release lock for VirusTotal API query.
-- Should be called after query completes (success or failure) or before returning on error.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
function cache.virustotal_release_lock(plugin, checksum)
	local lock_key = "plugin_malware_scan_virustotal_lock_" .. checksum
	plugin.cachestore:delete(lock_key)
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [VIRUSTOTAL] Released lock for checksum: %s",
		checksum:sub(1, 16) .. "..."))
end

-- Wait for another request to complete VirusTotal query and return the cached result.
-- Polls cache with exponential backoff until result appears or timeout occurs.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number File size for validation
--- @return boolean success
--- @return string|nil result
--- @return number|nil cached_size
--- @return string|nil error_msg
function cache.virustotal_wait_for_result(plugin, checksum, file_size)
	return cache_wait_for_result_generic(plugin, "virustotal", checksum, file_size)
end

--------------------------------------------------------------------------------
-- SENTINELONE LOCKING FUNCTIONS
--------------------------------------------------------------------------------

-- Try to acquire lock for SentinelOne API query (atomic operation to prevent concurrent queries).
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @return boolean acquired True if lock acquired, false if another thread holds lock
function cache.sentinelone_try_lock(plugin, checksum)
	local lock_key = "plugin_malware_scan_sentinelone_lock_" .. checksum
	local lock_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_LOCK_TTL"]) or 60

	local ok, err = plugin.cachestore:add(lock_key, "scanning", lock_ttl)

	if ok then
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [SENTINELONE] Acquired lock for checksum: %s (TTL: %ds)",
			checksum:sub(1, 16) .. "...", lock_ttl))
		return true
	else
		plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [SENTINELONE] Lock already held by another request: %s",
			checksum:sub(1, 16) .. "..."))
		return false
	end
end

-- Release lock for SentinelOne API query.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
function cache.sentinelone_release_lock(plugin, checksum)
	local lock_key = "plugin_malware_scan_sentinelone_lock_" .. checksum
	plugin.cachestore:delete(lock_key)
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE_LOCK] [SENTINELONE] Released lock for checksum: %s",
		checksum:sub(1, 16) .. "..."))
end

-- Wait for another request to complete SentinelOne query and return the cached result.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number File size for validation
--- @return boolean success
--- @return string|nil result
--- @return number|nil cached_size
--- @return string|nil error_msg
function cache.sentinelone_wait_for_result(plugin, checksum, file_size)
	return cache_wait_for_result_generic(plugin, "sentinelone", checksum, file_size)
end

--------------------------------------------------------------------------------
-- CACHE CHECK FUNCTIONS
--------------------------------------------------------------------------------

--- Check if VirusTotal scan result is in local cache.
--- Returns success boolean, cached result, and file size (for verification).
--- Cache format: "result|size|timestamp"
--- Note: Redis lookup is handled by get_composite_redis_cache() for performance.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number|nil File size for verification
--- @return boolean success True if cache hit
--- @return string|nil result Cached result or nil
--- @return number|nil cached_size Cached file size or nil
function cache.virustotal_check(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_virustotal_" .. checksum

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] is_in_vt_cache: checksum=%s", checksum:sub(1, 16) .. "..."))

	-- Check local cache (fast, ~1ms)
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|size|timestamp"
		local result, cached_size, timestamp = data:match("^([^|]+)|([^|]+)|([^|]+)$")
		if result then
			-- Verify file size matches
			if file_size and tonumber(cached_size) ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] VirusTotal cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, tonumber(cached_size)))
				return false, nil, nil
			end
			-- Verify TTL hasn't expired
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] VirusTotal cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] VirusTotal cache entry invalidated by cleanup marker - treating as MISS")
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] VirusTotal local cache HIT (size: %s bytes, age: %ds, TTL remaining: %ds)",
				cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end

	plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] VirusTotal local cache MISS")
	return false, nil, nil
end

--- Add VirusTotal scan result to local cache.
--- Stores: result, file size, and timestamp for verification and debugging.
--- Cache format: "result|size|timestamp"
--- Returns success boolean and error message if failed.
--- Note: Redis storage is handled by set_composite_redis_cache() for performance.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param value string Scan result ("clean" or detection info)
--- @param file_size number|nil File size in bytes
--- @return boolean success True if operation succeeded
--- @return string|nil error Error message if failed
function cache.virustotal_add(plugin, checksum, value, file_size)
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- This prevents false negatives if a file becomes identified as malware shortly after upload
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		logger.log_error( "[CACHE_CLEAN] VirusTotal result cached for " .. cache_ttl .. " seconds")
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		logger.log_error( "[CACHE_MALWARE] VirusTotal result cached for " .. cache_ttl .. " seconds")
	end

	local cache_key = "plugin_malware_scan_virustotal_" .. checksum

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] add_to_vt_cache: checksum=%s, value=%s, size=%d bytes, ttl=%ds",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))

	-- Store in local cache with structured format: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] Failed to store VirusTotal in local cache: " .. tostring(err))
		return false, err
	end
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] VirusTotal result stored in local cache (size: %d bytes)", file_size or 0))

	return true
end

--- Check if SentinelOne result is in local cache.
--- Cache format: "result|size|timestamp"
--- Returns success boolean, cached result, and file size (or nil values if not found).
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number|nil File size for verification
--- @return boolean success True if cache hit
--- @return string|nil result Cached result or nil
--- @return number|nil cached_size Cached file size or nil
function cache.sentinelone_check(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_sentinelone_" .. checksum

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] is_in_sentinelone_cache: checksum=%s, file_size=%d",
		checksum:sub(1, 16) .. "...", file_size or 0))

	-- Check local cache (fast, ~1ms)
	local ok, data = plugin.cachestore:get(cache_key)
	if ok and data then
		-- Parse cached data: "result|size|timestamp"
		local result, cached_size, timestamp = data:match("^([^|]+)|([^|]+)|([^|]+)$")
		if result then
			-- Verify file size matches to prevent collisions (same size can have different SHA256)
			if file_size and tonumber(cached_size) ~= file_size then
				plugin:log_debug(string.format(
					"[CACHE] SentinelOne cache size mismatch: expected %d, got %d - treating as MISS",
					file_size, tonumber(cached_size)))
				return false, nil, nil
			end

			-- Verify TTL hasn't expired
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] SentinelOne cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] SentinelOne cache entry invalidated by cleanup marker - treating as MISS")
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] SentinelOne local cache HIT (size: %s bytes, age: %ds, TTL remaining: %ds)",
				cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end

	plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] SentinelOne local cache MISS")
	return false, nil, nil
end

--- Add SentinelOne result to local cache.
--- Cache format: "result|size|timestamp"
--- Returns success boolean and error message if failed.
--- Note: Redis storage is handled by set_composite_redis_cache() for performance.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param value string Scan result ("clean" or detection info)
--- @param file_size number|nil File size in bytes
--- @return boolean success True if operation succeeded
--- @return string|nil error Error message if failed
function cache.sentinelone_add(plugin, checksum, value, file_size)
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- This prevents false negatives if a file becomes identified as malware shortly after upload
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		logger.log_error( "[CACHE_CLEAN] SentinelOne result cached for " .. cache_ttl .. " seconds")
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		logger.log_error( "[CACHE_MALWARE] SentinelOne result cached for " .. cache_ttl .. " seconds")
	end

	local cache_key = "plugin_malware_scan_sentinelone_" .. checksum

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] add_to_sentinelone_cache: checksum=%s, value=%s, size=%d bytes, ttl=%ds",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))

	-- Store in local cache with structured format: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] Failed to store SentinelOne in local cache: " .. tostring(err))
		return false, err
	end
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] SentinelOne result stored in local cache (size: %d bytes)", file_size or 0))

	return true
end

-- ============================================================================
-- MALWAREBAZAAR CACHE FUNCTIONS
-- ============================================================================

--- Check if MalwareBazaar result for checksum exists in local cache.
--- Returns: success boolean, cached value (or nil), cached file size (or nil)
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param file_size number|nil File size for verification
--- @return boolean success True if cache hit
--- @return string|nil result Cached result or nil
--- @return number|nil cached_size Cached file size or nil
function cache.malwarebazaar_check(plugin, checksum, file_size)
	local cache_key = "plugin_malware_scan_malwarebazaar_" .. checksum

	plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] Checking MalwareBazaar local cache for checksum: " .. checksum:sub(1, 16) .. "...")

	-- Check local cache first (fast path)
	local ok, cached_data = plugin.cachestore:get(cache_key)
	if ok and cached_data then
		-- Parse cache data: "result|size|timestamp"
		local result, cached_size, timestamp = cached_data:match("([^|]+)|([^|]+)|([^|]+)")
		if result then
			-- Check if entry is still valid based on TTL
			local cache_age = os.time() - tonumber(timestamp)
			local ttl
			if result == "clean" then
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean
			else
				ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
			if ttl > 604800 then ttl = 604800 end  -- Cap at 7 days max to prevent table growth
			end
			if cache_age > ttl then
				plugin:log_debug(string.format(
					"[CACHE] MalwareBazaar cache entry expired (age: %ds, TTL: %ds) - treating as MISS",
					cache_age, ttl))
				return false, nil, nil
			end

			-- Check if entry should be invalidated due to cleanup on restart
			if cache.should_invalidate_on_cleanup and cache.should_invalidate_on_cleanup(plugin, tonumber(timestamp)) then
				plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] MalwareBazaar cache entry invalidated by cleanup marker - treating as MISS")
				plugin.cachestore:delete(cache_key)
				return false, nil, nil
			end

			plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] MalwareBazaar local cache HIT (size: %s bytes, age: %ds, TTL remaining: %ds)",
				cached_size, cache_age, ttl - cache_age))
			return true, result, tonumber(cached_size)
		end
	end

	plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] MalwareBazaar local cache MISS")
	return false, nil, nil
end

--- Add MalwareBazaar result to local cache.
--- Cache format: "result|size|timestamp"
--- Returns success boolean and error message if failed.
--- Note: Redis storage is handled by set_composite_redis_cache() for performance.
--- @param plugin Plugin instance
--- @param checksum string SHA256 checksum
--- @param value string Scan result ("clean" or detection info)
--- @param file_size number|nil File size in bytes
--- @return boolean success True if operation succeeded
--- @return string|nil error Error message if failed
function cache.malwarebazaar_add(plugin, checksum, value, file_size)
	-- Differential caching: clean results cached for shorter period, malicious for longer
	-- This prevents false negatives if a file becomes identified as malware shortly after upload
	local cache_ttl
	if value == "clean" then
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_CLEAN_TTL"]) or 300  -- Default 5 minutes for clean files
		logger.log_error( "[CACHE_CLEAN] MalwareBazaar result cached for " .. cache_ttl .. " seconds")
	else
		cache_ttl = tonumber(plugin.variables["MALWARE_SCAN_CACHE_VIRUS_TTL"]) or 7776000  -- Default 90 days for malicious
		if cache_ttl > 7776000 then cache_ttl = 7776000 end  -- Cap at 90 days max to prevent unbounded growth
		logger.log_error( "[CACHE_MALWARE] MalwareBazaar result cached for " .. cache_ttl .. " seconds")
	end

	local cache_key = "plugin_malware_scan_malwarebazaar_" .. checksum

	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] add_to_malwarebazaar_cache: checksum=%s, value=%s, size=%d bytes, ttl=%ds",
		checksum:sub(1, 16) .. "...", value, file_size or 0, cache_ttl))

	-- Store in local cache with structured format: "result|size|timestamp"
	local cache_data = string.format("%s|%d|%d", value, file_size or 0, os.time())
	local ok, err = plugin.cachestore:set(cache_key, cache_data, cache_ttl)
	if not ok then
		plugin:log_debug("[v" .. cache.VERSION .. "] [CACHE] Failed to store MalwareBazaar in local cache: " .. tostring(err))
		return false, err
	end
	plugin:log_debug(string.format("[v" .. cache.VERSION .. "] [CACHE] MalwareBazaar result stored in local cache (size: %d bytes)", file_size or 0))

	return true
end

-- ============================================================================
-- CACHE CLEANUP ON RESTART
-- ============================================================================

--- Check if a cache entry should be invalidated based on cleanup marker.
--- Returns true if entry is older than cleanup marker (should be invalidated).
--- @param plugin Plugin instance
--- @param entry_timestamp number Timestamp of cache entry
--- @return boolean should_invalidate True if entry should be invalidated
function cache.should_invalidate_on_cleanup(plugin, entry_timestamp)
	local marker_key = "plugin_malware_scan_cleanup_marker"
	local ok, marker_value = plugin.cachestore:get(marker_key)

	if not ok or not marker_value then
		-- No cleanup marker exists, entry is valid
		return false
	end

	local cleanup_timestamp = tonumber(marker_value)
	if not cleanup_timestamp then
		-- Invalid marker format, treat entry as valid
		return false
	end

	-- Entry is older than cleanup marker, should be invalidated
	return entry_timestamp < cleanup_timestamp
end

--- Try to acquire distributed lock for cache cleanup.
--- Uses cachestore to ensure only one worker performs cleanup.
--- Returns true if lock was acquired, false if another worker has it.
---
--- NOTE: Uses atomic add() operation to prevent TOCTOU race condition (CWE-362).
--- If cachestore doesn't support add(), falls back to get+set (with race condition risk).
--- @param plugin Plugin instance
--- @return boolean acquired True if lock was acquired
function cache.lock_acquire(plugin)
	local lock_key = "plugin_malware_scan_cleanup_lock"
	local lock_ttl = 60  -- Lock expires after 60 seconds (safety timeout)

	-- Try atomic add() first (only succeeds if key doesn't exist)
	if plugin.cachestore.add then
		local add_ok, add_err = plugin.cachestore:add(lock_key, os.time(), lock_ttl)
		if add_ok then
			logger.log_notice( "[CACHE_CLEANUP] Distributed lock acquired successfully (atomic)")
			return true
		else
			-- Lock already exists or add() failed
			logger.log_notice( "[CACHE_CLEANUP] Lock already held by another worker")
			return false
		end
	end

	-- Fallback to get+set (has TOCTOU race condition, but better than nothing)
	logger.log_warn( "[CACHE_CLEANUP] cachestore doesn't support add(), using non-atomic fallback")

	local ok, err = plugin.cachestore:get(lock_key)
	if ok then
		-- Lock already exists
		logger.log_notice( "[CACHE_CLEANUP] Lock already held by another worker")
		return false
	end

	-- Lock doesn't exist, try to acquire it (race window here!)
	local set_ok, set_err = plugin.cachestore:set(lock_key, os.time(), lock_ttl)
	if not set_ok then
		logger.log_warn( "[CACHE_CLEANUP] Failed to acquire lock: " .. tostring(set_err))
		return false
	end

	logger.log_notice( "[CACHE_CLEANUP] Distributed lock acquired successfully (non-atomic)")
	return true
end

--- Release distributed lock for cache cleanup.
--- Removes the lock from cachestore to allow future cleanups.
--- @param plugin Plugin instance
--- @return boolean success True if lock was released
function cache.lock_release(plugin)
	local lock_key = "plugin_malware_scan_cleanup_lock"

	-- Delete the lock key
	local ok, err = plugin.cachestore:delete(lock_key)
	if not ok then
		logger.log_warn( "[CACHE_CLEANUP] Failed to release lock: " .. tostring(err))
		return false
	end

	logger.log_notice( "[CACHE_CLEANUP] Distributed lock released")
	return true
end

--- Clear all cached scan results on plugin restart.
--- Clears both local cache (cachestore) and Redis cache (clusterstore).
--- Uses marker-based approach for local cache (lazy invalidation).
--- Uses SCAN + UNLINK for Redis cache (pattern-based deletion).
--- This is useful after ClamAV signature updates or to resolve cache corruption.
--- Returns success boolean and statistics about cleanup.
--- @param plugin Plugin instance
--- @return boolean success True if cleanup succeeded
--- @return table stats Statistics about cleanup operation
function cache.cleanup_all(plugin)
	local stats = {
		local_cleared = 0,
		redis_cleared = 0,
		errors = 0,
		patterns_cleaned = 0,
		pattern_details = {},
		hash_reinitialized = false,
		start_time = os.time(),
		end_time = nil,
		duration_seconds = nil
	}

	logger.log_notice( "[CACHE_CLEANUP] Starting cache cleanup on restart")

	-- Clear local cache by setting cleanup marker timestamp
	-- BunkerWeb's cachestore doesn't have enumerate/flush methods,
	-- so we use a marker-based approach: set current timestamp as cleanup marker
	-- On subsequent cache lookups, entries older than this marker are treated as expired
	local cleanup_marker_key = "plugin_malware_scan_cleanup_marker"
	local cleanup_timestamp = os.time()
	local marker_ttl = 86400 * 7  -- Keep marker for 7 days (max cache TTL)

	local marker_ok, marker_err = plugin.cachestore:set(cleanup_marker_key, tostring(cleanup_timestamp), marker_ttl)
	if marker_ok then
		logger.log_notice( string.format(
			"[CACHE_CLEANUP] Local cache cleanup marker set (timestamp: %d). Old entries will be invalidated on next lookup.",
			cleanup_timestamp
		))
		stats.local_cleared = 1
	else
		logger.log_warn( "[CACHE_CLEANUP] Failed to set local cache cleanup marker: " .. tostring(marker_err))
		stats.errors = stats.errors + 1
	end

	-- Clear Redis cache if shared database is enabled
	local use_shared = plugin.variables["MALWARE_SCAN_USE_SHARED_DATABASE"] == "yes"
	local use_redis = plugin.ctx.bw.use_redis == "yes"

	-- Support granular cleanup: only clean patterns where flag is enabled
	local cleanup_all = plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_ALL"] == "yes"

	if use_shared and use_redis then
		-- Check if circuit breaker is open
		if database.should_skip(plugin) then
			logger.log_warn( "[CACHE_CLEANUP] Redis circuit breaker open, skipping Redis cleanup")
			return true, stats
		end

		logger.log_notice( "[CACHE_CLEANUP] Clearing Redis shared cache using SCAN + UNLINK")

		-- Connect to Redis
		local connect_ok, connect_err = plugin.clusterstore:connect()
		if not connect_ok then
			logger.log_warn( "[CACHE_CLEANUP] Failed to connect to Redis: " .. tostring(connect_err))
			stats.errors = stats.errors + 1
			database.failure_record(plugin)
			return true, stats
		end

		-- Clear plugin-related keys from Redis using SCAN + UNLINK
		-- UNLINK is non-blocking (async deletion), better than DEL
		-- Build pattern list based on enabled flags
		local redis_patterns = {}

		-- Check each scanner's cleanup flag (or cleanup_all master switch)
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_CLAMAV"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_clamav_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_VIRUSTOTAL"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_virustotal_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_SENTINELONE"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_sentinelone_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_MALWAREBAZAAR"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_malwarebazaar_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_ATTACKER_IPV4"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_attacker_ipv4_*")
		end
		if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_ATTACKER_IPV6"] == "yes" then
			table.insert(redis_patterns, "plugin_malware_scan_attacker_ipv6_*")
		end

		-- Always clean composite results cache if any scanner is being cleaned
		if #redis_patterns > 0 then
			table.insert(redis_patterns, "plugin_malware_scan_results_*")
		end

		-- If no patterns to clean, skip Redis cleanup
		if #redis_patterns == 0 then
			logger.log_notice( "[CACHE_CLEANUP] No Redis cache cleanup flags enabled, skipping Redis cleanup")
			plugin.clusterstore:close()
			return true, stats
		end

		-- Safety validation: verify all patterns have expected prefix
		local SAFE_PREFIX = "plugin_malware_scan_"
		for _, pattern in ipairs(redis_patterns) do
			if not pattern:match("^" .. SAFE_PREFIX) then
				logger.log_error( string.format(
					"[CACHE_CLEANUP] SAFETY ERROR: Pattern '%s' does not start with expected prefix '%s' - ABORTING cleanup",
					pattern,
					SAFE_PREFIX
				))
				plugin.clusterstore:close()
				stats.errors = stats.errors + 1
				return false, stats
			end
		end

		logger.log_notice( string.format(
			"[CACHE_CLEANUP] Cleaning %d Redis cache pattern(s): %s",
			#redis_patterns,
			table.concat(redis_patterns, ", ")
		))

		local total_keys_deleted = 0

		for _, pattern in ipairs(redis_patterns) do
			local cursor = "0"
			local keys_for_pattern = 0

			repeat
				-- SCAN returns: cursor, array of keys
				-- SCAN 0 MATCH pattern COUNT 100
				local scan_result, scan_err = plugin.clusterstore:call("scan", cursor, "MATCH", pattern, "COUNT", 100)

				if not scan_result then
					logger.log_warn( "[CACHE_CLEANUP] Redis SCAN failed for pattern " .. pattern .. ": " .. tostring(scan_err))
					stats.errors = stats.errors + 1
					database.failure_record(plugin)
					break
				end

				-- scan_result is a table: {new_cursor, {key1, key2, ...}}
				-- Validate scan_result structure to prevent nil dereference
				if type(scan_result) ~= "table" or #scan_result < 2 then
					logger.log_warn( "[CACHE_CLEANUP] Invalid Redis SCAN result format")
					stats.errors = stats.errors + 1
					break
				end

				cursor = scan_result[1]
				local keys = scan_result[2]

				-- Delete keys using UNLINK (non-blocking)
				if keys and #keys > 0 then
					-- Safety validation: verify each key has expected prefix before deletion
					local SAFE_PREFIX = "plugin_malware_scan_"
					local validated_keys = {}
					for _, key in ipairs(keys) do
						if key:match("^" .. SAFE_PREFIX) then
							table.insert(validated_keys, key)
						else
							logger.log_warn( string.format(
								"[CACHE_CLEANUP] SAFETY WARNING: Skipping key '%s' - does not match expected prefix '%s'",
								key,
								SAFE_PREFIX
							))
							stats.errors = stats.errors + 1
						end
					end

					-- Only unlink validated keys
					if #validated_keys > 0 then
						local unlink_result, unlink_err = plugin.clusterstore:call("unlink", unpack(validated_keys))
						if unlink_result then
							keys_for_pattern = keys_for_pattern + tonumber(unlink_result)
							database.success_record(plugin)
						else
							logger.log_warn( "[CACHE_CLEANUP] Redis UNLINK failed: " .. tostring(unlink_err))
							stats.errors = stats.errors + 1
							database.failure_record(plugin)
						end
					end
				end

			until cursor == "0"

			if keys_for_pattern > 0 then
				logger.log_notice( string.format(
					"[CACHE_CLEANUP] Deleted %d keys matching pattern: %s",
					keys_for_pattern,
					pattern
				))
				total_keys_deleted = total_keys_deleted + keys_for_pattern
				stats.patterns_cleaned = stats.patterns_cleaned + 1
				table.insert(stats.pattern_details, {
					pattern = pattern,
					keys_deleted = keys_for_pattern
				})
			end
		end

		-- Close Redis connection
		plugin.clusterstore:close()

		stats.redis_cleared = total_keys_deleted
		logger.log_notice( string.format(
			"[CACHE_CLEANUP] Redis cleanup complete - deleted %d keys total",
			total_keys_deleted
		))
	else
		logger.log_notice( "[CACHE_CLEANUP] Redis shared cache disabled, skipping Redis cleanup")
	end

	-- After cache cleanup, check if MalwareBazaar is enabled and reinitialize hashes
	if plugin.variables["MALWARE_SCAN_CUSTOM_HASHES_ENABLED"] == "yes" and
	   plugin.variables["MALWARE_SCAN_CUSTOM_HASHES_AUTO_UPDATE"] == "yes" then

		logger.log_notice( "[CACHE_CLEANUP] MalwareBazaar hashes enabled - attempting to reinitialize hash database")

		-- Try to call the hash update job script
		local update_script = "/etc/bunkerweb/plugins/malware-scan/jobs/malware-scan-update.py"
		-- Check if script exists using native Lua (non-blocking)
		local script_attr = lfs.attributes(update_script, "mode")
		if script_attr == "file" then
			logger.log_notice( "[CACHE_CLEANUP] Found malware-scan-update.py, triggering hash redownload")

			-- Execute script in background asynchronously
			-- Using nohup to detach from this process
			local cmd = "nohup python3 " .. ms_utils.shell_escape_path(update_script) .. " > /dev/null 2>&1 &"
			local result = os.execute(cmd)

			if result == 0 then
				logger.log_notice( "[CACHE_CLEANUP] Hash update job triggered successfully")
				stats.hash_reinitialized = true
			else
				logger.log_warn( "[CACHE_CLEANUP] Failed to trigger hash update job, will be handled by scheduler")
				stats.errors = stats.errors + 1
			end
		else
			logger.log_warn( "[CACHE_CLEANUP] malware-scan-update.py not found at " .. update_script .. ", hashes will be updated by scheduler")
			stats.errors = stats.errors + 1
		end
	end

	-- Clean up downloaded MalwareBazaar files and caches
	if cleanup_all or plugin.variables["MALWARE_SCAN_CACHE_CLEANUP_ON_RESTART_MALWAREBAZAAR"] == "yes" then
		logger.log_notice( "[CACHE_CLEANUP] Cleaning up MalwareBazaar downloaded files and caches...")

		local mb_files_cleaned = 0

		-- Remove CSV hash file if it exists
		local csv_path = plugin.variables["MALWARE_SCAN_CUSTOM_HASHES_CSV_PATH"]
		if csv_path and csv_path ~= "" then
			if os.remove(csv_path) then
				logger.log_notice( string.format("[v" .. cache.VERSION .. "] [CACHE_CLEANUP] Removed CSV hash file: %s", csv_path))
				mb_files_cleaned = mb_files_cleaned + 1
			end
		end

		-- Remove temporary extraction directory if it exists (native Lua, non-blocking)
		local temp_extract_dir = "/tmp/malware-scan-hashes"
		local temp_attr = lfs.attributes(temp_extract_dir, "mode")
		if temp_attr == "directory" then
			if remove_directory_recursive(temp_extract_dir) then
				logger.log_notice( string.format("[v" .. cache.VERSION .. "] [CACHE_CLEANUP] Removed temporary extraction directory: %s", temp_extract_dir))
				mb_files_cleaned = mb_files_cleaned + 1
			end
		end

		-- Remove downloaded ZIP files from cache directory (native Lua, non-blocking)
		local cache_dir = "/var/cache/bunkerweb/malware-scan"
		local cache_attr = lfs.attributes(cache_dir, "mode")
		if cache_attr == "directory" then
			local zip_count = 0
			for filename in lfs.dir(cache_dir) do
				if filename:match("%.zip$") then
					local file_path = cache_dir .. "/" .. filename
					local file_attr = lfs.attributes(file_path, "mode")
					if file_attr == "file" then
						if os.remove(file_path) then
							zip_count = zip_count + 1
						end
					end
				end
			end
			if zip_count > 0 then
				logger.log_notice( string.format("[v" .. cache.VERSION .. "] [CACHE_CLEANUP] Cleaned up %d ZIP file(s) from cache directory: %s", zip_count, cache_dir))
				mb_files_cleaned = mb_files_cleaned + 1
			end
		end

		if mb_files_cleaned > 0 then
			stats.local_cleared = stats.local_cleared + mb_files_cleaned
			logger.log_notice( string.format("[v" .. cache.VERSION .. "] [CACHE_CLEANUP] MalwareBazaar file cleanup completed - %d items removed", mb_files_cleaned))
		else
			logger.log_notice( "[CACHE_CLEANUP] MalwareBazaar file cleanup: no files to remove")
		end
	end

	-- Calculate total duration
	stats.end_time = os.time()
	stats.duration_seconds = stats.end_time - stats.start_time

	-- Log cleanup statistics summary
	local pattern_summary = ""
	if stats.patterns_cleaned > 0 then
		local pattern_list = {}
		for _, detail in ipairs(stats.pattern_details) do
			table.insert(pattern_list, string.format("%s (%d)", detail.pattern, detail.keys_deleted))
		end
		pattern_summary = " - Patterns: " .. table.concat(pattern_list, ", ")
	end

	logger.log_notice( string.format(
		"[CACHE_CLEANUP]  CLEANUP STATISTICS - Local: %d, Redis patterns: %d (%d keys), Hash reinit: %s, Errors: %d, Duration: %ds%s",
		stats.local_cleared,
		stats.patterns_cleaned,
		stats.redis_cleared,
		stats.hash_reinitialized and "yes" or "no",
		stats.errors,
		stats.duration_seconds,
		pattern_summary
	))

	return true, stats
end

-- Return module
return cache
