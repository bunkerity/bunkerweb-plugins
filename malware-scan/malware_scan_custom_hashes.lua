-- BunkerWeb Malware Scan - Custom Hash Database Module
-- Optimized for large threat feeds (1M+ hashes from MalwareBazaar, etc.)
--
-- Features:
-- - Redis-backed storage for 1M+ hashes (~200MB) distributed across 16 buckets
-- - Bucketed hash keys (malware_scan:hashes:0-9, A-F) for 16x faster lookups
-- - Sub-millisecond hash lookups via first-character bucketing
-- - Batch import for large CSV files with deduplication
-- - Automatic daily updates from threat feeds with ETag caching
-- - Infinite persistence (freshness maintained by scheduler)
-- - Optional local cache for most-frequently-matched hashes

local cjson = require("cjson")
local logger = require("malware_scan_logger")
local utils = require("malware_scan_utils")
local database = require("malware_scan_database")

local ngx = ngx

local custom_hashes = {}

-- Module version
custom_hashes.VERSION = "0.8.0"

--------------------------------------------------------------------------------
-- REDIS-BASED STORAGE (Optimized for 1M+ hashes)
--------------------------------------------------------------------------------

-- Check if hash exists in custom database
--- @param plugin Plugin instance
--- @param checksum string SHA256 hash (64 hex chars)
--- @return boolean found True if hash was found in database
--- @return string|nil malware_name Malware name if found
function custom_hashes.check(plugin, checksum)
	-- Check if feature is enabled and Redis is available
	if not database.is_available(plugin) then
		return false, nil
	end

	-- Only check custom hashes if feature is enabled
	if plugin.variables and plugin.variables["MALWARE_SCAN_CUSTOM_HASHES_ENABLED"] ~= "yes" then
		return false, nil
	end

	-- Use bucketed key based on first character of SHA256 (64x faster lookups)
	-- Store format: HSET hash_db <sha256> <malware_name>|<signature_type>|<reporter>
	local hash_key = utils.get_hash_bucket(checksum)
	local data = database.hget(plugin, hash_key, checksum)

	if not data or data == ngx.null then
		-- Hash not found
		return false, nil
	end

	-- Parse stored data: "malware_name|signature_type|reporter"
	local malware_name = data:match("^([^|]+)")

	if not malware_name then
		return false, nil
	end

	-- Found match
	logger.log_error( string.format(
		"[CUSTOM_HASH] âœ“ MATCH: %s = %s (bucket: %s)",
		checksum:sub(1, 16) .. "...",
		utils.log_sanitize(malware_name),
		hash_key:sub(-1)
	))

	return true, malware_name
end

-- Add single hash to database
--- @param plugin Plugin instance
--- @param checksum string SHA256 hash
--- @param malware_name string Malware detection name
--- @param metadata string Optional metadata (signature_type|reporter)
--- @return boolean success True if hash was added
--- @return string|nil error Error message if failed
function custom_hashes.add(plugin, checksum, malware_name, metadata)
	if not database.is_available(plugin) then
		return false, "Redis not available"
	end

	-- Only add if custom hashes are enabled
	if plugin.variables and plugin.variables["MALWARE_SCAN_CUSTOM_HASHES_ENABLED"] ~= "yes" then
		return false, "Custom hashes feature is disabled"
	end

	metadata = metadata or ""
	-- Use bucketed key based on first character of SHA256
	local hash_key = utils.get_hash_bucket(checksum)
	local data = malware_name .. "|" .. metadata

	database.hset(plugin, hash_key, checksum, data)
	return true
end

-- Bulk add hashes (optimized for batch import with bucketing)
--- @param plugin Plugin instance
--- @param hashes table Array of {sha256, malware_name, metadata}
--- @return number added Number of hashes added
--- @return number duplicates Number of duplicate hashes skipped
function custom_hashes.bulk_add(plugin, hashes)
	if not database.is_available(plugin) then
		return 0, 0
	end

	if #hashes == 0 then
		return 0, 0
	end

	local duplicates = 0
	local to_add = {}

	-- First pass: identify duplicates vs new hashes
	for _, hash_entry in ipairs(hashes) do
		local sha256 = hash_entry[1]

		if custom_hashes.exists(plugin, sha256) then
			duplicates = duplicates + 1
		else
			table.insert(to_add, hash_entry)
		end
	end

	-- Second pass: add only new hashes (grouped by bucket for efficiency)
	if #to_add == 0 then
		return 0, duplicates
	end

	local pipeline = database.pipeline(plugin, #to_add)

	for _, hash_entry in ipairs(to_add) do
		local sha256 = hash_entry[1]
		local malware_name = hash_entry[2]
		local metadata = hash_entry[3] or ""
		local data = malware_name .. "|" .. metadata
		-- Use bucketed key based on first character of SHA256
		local hash_key = utils.get_hash_bucket(sha256)

		pipeline:hset(hash_key, sha256, data)
	end

	-- Execute pipeline
	local results = pipeline:commit()
	local added = 0

	for _, result in ipairs(results) do
		if result then
			added = added + 1
		end
	end

	return added, duplicates
end

-- Bulk add hashes with duplicate detection (for recent additions)
--- @param plugin Plugin instance
--- @param hashes table Array of {sha256, malware_name, metadata}
--- @return number added Number of hashes added
--- @return number duplicates Number of duplicate hashes skipped
function custom_hashes.bulk_add_with_duplicates(plugin, hashes)
	if not database.is_available(plugin) then
		return 0, 0
	end

	if #hashes == 0 then
		return 0, 0
	end

	local duplicates = 0
	local to_add = {}

	-- First pass: identify duplicates vs new hashes
	for _, hash_entry in ipairs(hashes) do
		local sha256 = hash_entry[1]

		if custom_hashes.exists(plugin, sha256) then
			duplicates = duplicates + 1
		else
			table.insert(to_add, hash_entry)
		end
	end

	-- Second pass: add only new hashes (grouped by bucket)
	if #to_add == 0 then
		return 0, duplicates
	end

	local pipeline = database.pipeline(plugin, #to_add)

	for _, hash_entry in ipairs(to_add) do
		local sha256 = hash_entry[1]
		local malware_name = hash_entry[2]
		local metadata = hash_entry[3] or ""
		local data = malware_name .. "|" .. metadata
		-- Use bucketed key based on first character of SHA256
		local hash_key = utils.get_hash_bucket(sha256)

		pipeline:hset(hash_key, sha256, data)
	end

	-- Execute pipeline
	local results = pipeline:commit()
	local added = 0

	for _, result in ipairs(results) do
		if result then
			added = added + 1
		end
	end

	return added, duplicates
end

-- Check if hash already exists (duplicate detection)
--- @param plugin Plugin instance
--- @param checksum string SHA256 hash
--- @return boolean exists True if hash exists in database
function custom_hashes.exists(plugin, checksum)
	if not database.is_available(plugin) then
		return false
	end

	-- Use bucketed key based on first character of SHA256
	local hash_key = utils.get_hash_bucket(checksum)
	local exists = database.hexists(plugin, hash_key, checksum)

	return exists == 1
end

-- Count total hashes across all buckets
--- @param plugin Plugin instance
--- @return number total Total number of hashes across all buckets
function custom_hashes.count(plugin)
	if not database.is_available(plugin) then
		return 0
	end

	-- Sum hash counts across all 16 buckets
	local total_count = 0
	local buckets = utils.get_all_hash_buckets()

	for _, bucket_key in ipairs(buckets) do
		local count = database.hlen(plugin, bucket_key)
		total_count = total_count + (tonumber(count) or 0)
	end

	return total_count
end

-- Clear all hashes from all buckets
--- @param plugin Plugin instance
--- @return boolean success True if all buckets were cleared
function custom_hashes.clear(plugin)
	if not database.is_available(plugin) then
		return false
	end

	-- Delete all 16 bucket keys (using UNLINK for non-blocking deletion)
	local buckets = utils.get_all_hash_buckets()
	local pipeline = database.pipeline(plugin, #buckets)

	if not pipeline then
		logger.log_error("[CUSTOM_HASHES] Failed to create Redis pipeline")
		return false
	end

	for _, bucket_key in ipairs(buckets) do
		pipeline:unlink(bucket_key)
	end

	pipeline:commit()
	return true
end

--------------------------------------------------------------------------------
-- CSV IMPORT (Optimized for MalwareBazaar format)
--------------------------------------------------------------------------------

-- Parse MalwareBazaar CSV line
-- Format: "first_seen_utc","sha256_hash","md5_hash","sha1_hash","reporter","file_name","file_type_guess","mime_type","signature","clamav","vtpercent","imphash","ssdeep","tlsh"
--- @return string|nil sha256 SHA256 hash if line is valid
--- @return string|nil malware_name Malware name if line is valid
--- @return string|nil metadata Metadata string if line is valid
local function custom_hashes_parse_bazaar_line(line)
	-- Extract quoted CSV fields
	local fields = {}
	for field in line:gmatch('"([^"]*)"') do
		table.insert(fields, field)
	end

	if #fields < 10 then
		return nil  -- Invalid line (need at least 10 fields)
	end

	local first_seen = fields[1]
	local sha256 = fields[2]
	local reporter = fields[5]
	local file_name = fields[6]
	local signature = fields[9]
	local clamav = fields[10]

	-- Validate SHA256 (64 hex chars)
	if not sha256 or #sha256 ~= 64 or not sha256:match("^%x+$") then
		return nil
	end

	-- Determine malware name (prefer signature, then clamav, then Unknown)
	-- reporter is not a valid malware description (it's the organization name)
	local malware_name = signature
	if malware_name == "n/a" or malware_name == "" then
		malware_name = clamav
	end
	if malware_name == "n/a" or malware_name == "" then
		malware_name = "Unknown"
	end

	local metadata = signature .. "|" .. clamav

	return sha256, malware_name, metadata
end

-- Import CSV file (MalwareBazaar format)
--- @param plugin Plugin instance
--- @param csv_path string Path to CSV file
--- @return boolean success True if import completed
--- @return number imported Number of hashes imported
--- @return number duplicates Number of duplicate hashes skipped
--- @return number errors Number of parsing errors
function custom_hashes.import_csv(plugin, csv_path)
	if not database.is_available(plugin) then
		return false, 0, 0, 0
	end

	local file, err = io.open(csv_path, "r")
	if not file then
		logger.log_error( "[CUSTOM_HASH] Failed to open CSV: " .. utils.log_sanitize(tostring(err)))
		return false, 0, 0, 0
	end

	local imported = 0
	local duplicates = 0
	local errors = 0
	local line_num = 0
	local batch = {}
	local batch_size = 1000  -- Import in batches of 1000 for efficiency

	logger.log_notice( "[CUSTOM_HASH] Starting CSV import: " .. csv_path)

	for line in file:lines() do
		line_num = line_num + 1

		-- Skip header and comment lines
		if line:match("^#") then
			goto continue_line
		end
		if line_num == 1 and line:match("^first_seen_utc") then
			goto continue_line
		end

		-- Parse line
		local sha256, malware_name, metadata = custom_hashes_parse_bazaar_line(line)

		if not sha256 then
			errors = errors + 1
			if errors <= 10 then  -- Log first 10 errors only
				logger.log_warn( string.format(
					"[CUSTOM_HASH] Invalid line %d (skipping): %.50s", line_num, utils.log_sanitize(line)))
			end
			goto continue_line
		end

		-- Add to batch
		table.insert(batch, {sha256, malware_name, metadata})

		-- Bulk add when batch is full
		if #batch >= batch_size then
			local added, dupes = custom_hashes.bulk_add(plugin, batch)
			imported = imported + added
			duplicates = duplicates + dupes
			batch = {}

			-- Progress indicator (every 100K hashes)
			if (imported + duplicates) % 100000 == 0 then
				logger.log_notice( string.format(
					"[CUSTOM_HASH] Progress: %d new, %d duplicates (total processed: %d)",
					imported, duplicates, imported + duplicates))
			end
		end

		::continue_line::
	end

	-- Import remaining batch
	if #batch > 0 then
		local added, dupes = custom_hashes.bulk_add(plugin, batch)
		imported = imported + added
		duplicates = duplicates + dupes
	end

	file:close()

	logger.log_notice( string.format(
		"[CUSTOM_HASH] CSV import complete: %d new, %d duplicates, %d errors (total: %d hashes)",
		imported, duplicates, errors, custom_hashes.count(plugin)))

	return true, imported, duplicates, errors
end

-- Import CSV with duplicate detection (for recent additions)
--- @param plugin Plugin instance
--- @param csv_path string Path to CSV file
--- @return boolean success True if import completed
--- @return number imported Number of hashes imported
--- @return number duplicates Number of duplicate hashes skipped
--- @return number errors Number of parsing errors
function custom_hashes.import_csv_recent(plugin, csv_path)
	if not database.is_available(plugin) then
		return false, 0, 0, 0
	end

	local file, err = io.open(csv_path, "r")
	if not file then
		logger.log_error( "[CUSTOM_HASH] Failed to open CSV: " .. utils.log_sanitize(tostring(err)))
		return false, 0, 0, 0
	end

	local imported = 0
	local duplicates = 0
	local errors = 0
	local line_num = 0
	local batch = {}
	local batch_size = 1000

	logger.log_notice( "[CUSTOM_HASH] Starting recent CSV import (with duplicate detection): " .. csv_path)

	for line in file:lines() do
		line_num = line_num + 1

		-- Skip header and comment lines
		if line:match("^#") then
			goto continue_line
		end
		if line_num == 1 and line:match("^first_seen_utc") then
			goto continue_line
		end

		-- Parse line
		local sha256, malware_name, metadata = custom_hashes_parse_bazaar_line(line)

		if not sha256 then
			errors = errors + 1
			if errors <= 10 then
				logger.log_warn( string.format(
					"[CUSTOM_HASH] Invalid line %d (skipping): %.50s", line_num, line))
			end
			goto continue_line
		end

		-- Add to batch
		table.insert(batch, {sha256, malware_name, metadata})

		-- Process batch when full
		if #batch >= batch_size then
			local added, dupes = custom_hashes.bulk_add_with_duplicates(plugin, batch)
			imported = imported + added
			duplicates = duplicates + dupes
			batch = {}

			-- Progress indicator
			if (imported + duplicates) % 100000 == 0 then
				logger.log_notice( string.format(
					"[CUSTOM_HASH] Progress: %d new, %d duplicates (total processed: %d)",
					imported, duplicates, imported + duplicates))
			end
		end

		::continue_line::
	end

	-- Import remaining batch
	if #batch > 0 then
		local added, dupes = custom_hashes.bulk_add_with_duplicates(plugin, batch)
		imported = imported + added
		duplicates = duplicates + dupes
	end

	file:close()

	logger.log_notice( string.format(
		"[CUSTOM_HASH] Recent import complete: %d new, %d duplicates, %d errors (total: %d hashes)",
		imported, duplicates, errors, custom_hashes.count(plugin)))

	return true, imported, duplicates, errors
end

-- Export custom hashes to CSV from all buckets
--- @param plugin Plugin instance
--- @param csv_path string Path to output CSV file
--- @return boolean success True if export completed
--- @return number exported Number of hashes exported
function custom_hashes.export_csv(plugin, csv_path)
	if not database.is_available(plugin) then
		return false, 0
	end

	local file, file_err = io.open(csv_path, "w")

	if not file then
		logger.log_error( "[CUSTOM_HASH] Failed to open output CSV: " .. tostring(file_err))
		return false, 0
	end

	-- Write CSV header (MalwareBazaar compatible)
	file:write("sha256,malware_name,signature_type,reporter\n")

	-- Scan all hashes from all buckets
	local exported = 0
	local buckets = utils.get_all_hash_buckets()

	for _, hash_key in ipairs(buckets) do
		local cursor = "0"

		repeat
			local result = database.hscan(plugin, hash_key, cursor)
			if not result then
				break
			end

			cursor = tostring(result[1]) or "0"
			local hashes = result[2] or {}

			-- Process hashes in pairs (key, value)
			for i = 1, #hashes, 2 do
				local sha256 = hashes[i]
				local data = hashes[i + 1]

				if sha256 and data then
					-- Parse data: "malware_name|signature_type|reporter"
					local parts = {}
					for part in data:gmatch("[^|]+") do
						table.insert(parts, part)
					end

					local malware_name = parts[1] or "unknown"
					local signature = parts[2] or ""
					local reporter = parts[3] or ""

					file:write(string.format("%s,%s,%s,%s\n",
						sha256, malware_name, signature, reporter))

					exported = exported + 1
				end
			end
		until cursor == "0"
	end

	file:close()

	logger.log_notice( string.format(
		"[CUSTOM_HASH] CSV export complete: %d hashes exported from %d buckets",
		exported, #buckets))

	return true, exported
end

--------------------------------------------------------------------------------
-- DAILY UPDATE MECHANISM
--------------------------------------------------------------------------------

-- Download CSV from URL
--- @return boolean success True if download completed
--- @return string|nil error Error message if download failed
local function custom_hashes_download_file(url, dest_path, timeout_ms)
	timeout_ms = timeout_ms or 30000  -- 30 second timeout

	local httpc = require("resty.http").new()
	httpc:set_timeout(timeout_ms)

	local res, err = httpc:request_uri(url, {
		method = "GET",
		ssl_verify = true
	})

	if not res then
		return false, "HTTP request failed: " .. tostring(err)
	end

	if res.status ~= 200 then
		return false, "HTTP " .. res.status
	end

	-- Write to temporary file
	local temp_path = dest_path .. ".tmp"
	local file, file_err = io.open(temp_path, "w")

	if not file then
		return false, "Failed to write file: " .. tostring(file_err)
	end

	file:write(res.body)
	file:close()

	-- Atomic rename
	local ok, rename_err = os.rename(temp_path, dest_path)
	if not ok then
		return false, "Failed to move file: " .. tostring(rename_err)
	end

	return true
end

-- Daily update task
--- @param plugin Plugin instance
--- @return boolean success True if daily update completed successfully
function custom_hashes.daily_update(plugin)
	local enabled = plugin.variables["MALWARE_SCAN_CUSTOM_HASH_AUTO_UPDATE"] or "no"
	if enabled ~= "yes" then
		return true  -- Auto-update disabled
	end

	local update_url = plugin.variables["MALWARE_SCAN_CUSTOM_HASH_UPDATE_URL"] or ""
	if update_url == "" then
		logger.log_warn( "[CUSTOM_HASH] Auto-update enabled but no URL configured")
		return false
	end

	local csv_path = plugin.variables["MALWARE_SCAN_CUSTOM_HASH_CSV_PATH"] or "/var/cache/bunkerweb/malware-scan/hashes.csv"

	logger.log_notice( "[CUSTOM_HASH] Starting daily update from: " .. update_url)

	-- Download CSV
	local ok, err = custom_hashes_download_file(update_url, csv_path)
	if not ok then
		logger.log_error( "[CUSTOM_HASH] Download failed: " .. tostring(err))
		return false
	end

	logger.log_notice( "[CUSTOM_HASH] Downloaded, now importing...")

	-- Clear old hashes
	custom_hashes.clear(plugin)

	-- Import new CSV
	local import_ok, imported, import_errors = custom_hashes.import_csv(plugin, csv_path)

	if not import_ok then
		logger.log_error( "[CUSTOM_HASH] Import failed")
		return false
	end

	logger.log_notice( string.format(
		"[CUSTOM_HASH] Daily update complete: %d hashes imported, %d errors",
		imported, import_errors))

	return true
end

--------------------------------------------------------------------------------
-- METRICS INTEGRATION
--------------------------------------------------------------------------------

-- Record hash check metric (if metrics module available)
function custom_hashes.record_metric(scanner_name, found)
	local metrics_ok, metrics = pcall(require, "malware_scan_metrics")

	if metrics_ok and metrics then
		if found then
			-- Hash database hit
			if metrics.custom_hash_hits then
				metrics.custom_hash_hits:inc(1)
			end
		end

		-- Always record check
		if metrics.custom_hash_checks then
			metrics.custom_hash_checks:inc(1)
		end
	end
end

--------------------------------------------------------------------------------
-- PUBLIC API
--------------------------------------------------------------------------------

return custom_hashes
